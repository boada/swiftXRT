{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "from tqdm import tqdm_notebook\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def parallel_process(array, function, n_jobs=None, use_kwargs=False, front_num=0):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the \n",
    "                parallel job. This can be useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    #We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "    #If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        [function(**a) if use_kwargs else function(a) for a in tqdm_notebook(array[front_num:])]\n",
    "        return \n",
    "    #Assemble the workers\n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        #Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': False,\n",
    "            'leave': True\n",
    "        }\n",
    "        #Print out the progress as tasks complete\n",
    "        for f in tqdm_notebook(as_completed(futures), **kwargs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_model(So, r, rc, beta):\n",
    "    ''' Beta model with 3 parameters. \n",
    "    So -- normalization\n",
    "    rc -- core radius\n",
    "    beta -- powerlaw slope\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return So * ( 1.0 + (r / rc)**2)**(-3.0 * beta + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(model, y, y_err):\n",
    "    '''Chi error. We are going to square this to make it the chi2 error.'''\n",
    "    return np.sum(((model - y) / y_err)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def like(theta, x, y, yerr):\n",
    "    So, rc, beta, bg = theta\n",
    "    model = beta_model(So, x, rc, beta) + bg\n",
    "    #return -0.5 * np.sum(np.log(2 * np.pi * yerr) + (y - model)**2 / yerr)\n",
    "    return -chi2(model, y, yerr)\n",
    "\n",
    "def prior(theta):\n",
    "    So, rc, beta, bg = theta\n",
    "    if So < 0:\n",
    "        return -np.inf\n",
    "    elif rc < 0 or rc > 10:\n",
    "        return -np.inf\n",
    "    elif beta < 0 or beta > 3: \n",
    "        return -np.inf\n",
    "    elif bg < 0 or bg > 1:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def prob(theta, x, y, yerr):\n",
    "    lp = prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + like(theta, x, y, yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_profile(name, outpath):\n",
    "    \n",
    "    # swift pixelscale in degrees\n",
    "    pixsc =  6.548089E-04 * 3600\n",
    "    \n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "        # now we need to read the individual detections\n",
    "        detects = Table.read(srcs, hdu=1)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    # we are going to fit profiles to the top 3 biggest \n",
    "    detects.sort(['SRC_AREA'], reverse=True)\n",
    "    \n",
    "    # open a file to write out the results\n",
    "    outfile = open(f'{outpath}/{name}/{name}_mcmcfits.txt', 'w')    \n",
    "    outfile.write('# Field ID So_50 So_84 So_16 rc_50 rc_84 rc_16 beta_50 beta_84 beta_16 bg_50 bg_84 bg_16\\n')\n",
    "    \n",
    "    # loop over the sources -- only the first 3\n",
    "    for i in detects['INDEX'][:3]:\n",
    "        \n",
    "        if os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}.radprof'):\n",
    "            data = Table.read(f'{outpath}/{name}/{name}_vtp_{i}.radprof', format='ascii', header_start=2)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        # don't try to fit things if there isn't any data\n",
    "        if len(data) <= 60:\n",
    "            continue\n",
    "        \n",
    "        # x-axis, in arcminutes\n",
    "        x = (data['r1'] + data['r2'])/ 2. / 60. * pixsc\n",
    "        \n",
    "        # this is the parameter fitting\n",
    "        ndim = 4  # number of parameters in the model\n",
    "        nwalkers = 100  # number of MCMC walkers\n",
    "        nburn = 100  # \"burn-in\" period to let chains stabilize\n",
    "        nsteps = 500  # number of MCMC steps to take\n",
    "\n",
    "        pos = [np.array([0.001, 1., 1., 0.001]) + 1e-4 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, prob, args=(x, data['sb'], data['sb_err']))\n",
    "        sampler.run_mcmc(pos, nsteps)\n",
    "        emcee_trace = sampler.get_chain(discard=nburn, thin=15, flat=True)\n",
    "        \n",
    "        # plot the result\n",
    "        fignum = np.random.randint(1, 1000)\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6.5, 5), num=fignum)\n",
    "        # data\n",
    "        ax.errorbar(x, data['sb'], yerr=data['sb_err'], fmt='o', label='data')\n",
    "        for So, rc, beta, bg in emcee_trace[np.random.randint(len(emcee_trace), size=100)]:\n",
    "            ax.plot(x, beta_model(So, x, rc, beta) + bg, color='k', alpha=0.1)\n",
    "        ylims = ax.get_ylim()\n",
    "        \n",
    "        #fit -- median (and error) values\n",
    "        So, rc, beta, bg = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(emcee_trace, [16, 50, 84], axis=0)))\n",
    "        ax.plot(x, beta_model(So[0], x, rc[0], beta[0]) + bg[0], label=r'$\\beta$ + bg')\n",
    "        ax.plot(x, beta_model(So[0], x, rc[0], beta[0]), label=r'$\\beta$')\n",
    "        \n",
    "        # write out the fit parameters\n",
    "        outfile.write(f'{name} ')\n",
    "        outfile.write(f'{i} ')\n",
    "        outfile.write(f'{So[0]:.5f} {So[1]:.5f} {So[2]:.5f} ')\n",
    "        outfile.write(f'{rc[0]:.5f} {rc[1]:.5f} {rc[2]:.5f} ')\n",
    "        outfile.write(f'{beta[0]:.5f} {beta[1]:.5f} {beta[2]:.5f} ')\n",
    "        outfile.write(f'{bg[0]:.5f} {bg[1]:.5f} {bg[2]:.5f}\\n')\n",
    "\n",
    "        # rc and bg lines\n",
    "        ax.axhline(bg[0], label='bg', zorder=0, lw=1)\n",
    "        ax.axvline(rc[0], zorder=0, lw=1)\n",
    "        \n",
    "        ax.semilogy()\n",
    "\n",
    "        if ylims[0] < 1e-5:\n",
    "            ax.text(rc[0] + 0.1, 2e-5, f\"rc = {rc[0]:.2f}'\", rotation='vertical', ha='left')\n",
    "            ax.set_ylim(1e-5, ylims[1])\n",
    "        else:\n",
    "            ax.text(rc[0] + 0.1, ylims[0], f\"rc = {rc[0]:.2f}'\", rotation='vertical', ha='left')\n",
    "            ax.set_ylim(ylims)\n",
    "        ax.set_xlabel('Radius [arcmin]')\n",
    "        ax.set_ylabel('Flux [cnts/s]')\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        fig.savefig(f'{outpath}/{name}/{name}_radproffit_{i}.png', bbox='tight', dpi=180)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # add a corner plot of the fits.\n",
    "        # plot the bg and So in log to make them fit on the plot better\n",
    "        emcee_trace[:,0] = np.log(emcee_trace[:,0])\n",
    "        emcee_trace[:,3] = np.log(emcee_trace[:,3])\n",
    "        f = corner.corner(emcee_trace, labels=['log So', 'rc', r'$\\beta$', 'log bg'],\n",
    "                    bins=[50, 50, 50, 50],\n",
    "                    smooth=True,\n",
    "                    fill_contours=True)\n",
    "\n",
    "        f.savefig(f'{outpath}/{name}/{name}_corner_{i}.png', bbox='tight')\n",
    "        plt.close(f)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc60dd6ba3cd43479953ee779755c026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1943), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "parallel_process(arr, fit_profile, use_kwargs=True, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = Table.read('./data_full/PSZ1_G083.35+76.41/PSZ1_G083.35+76.41_vtp_7.radprof', format='ascii', header_start=2)\n",
    "# d = Table.read('./data_full/PSZ1_G057.42-10.77/PSZ1_G057.42-10.77_vtp_2.radprof', format='ascii', header_start=2)\n",
    "# d = Table.read('./data_full/PSZ2_G356.21-43.11/PSZ2_G356.21-43.11_vtp_0.radprof', format='ascii', header_start=2)\n",
    "#d = Table.read('./data_full/PSZ2_G003.21-76.04/PSZ2_G003.21-76.04_vtp_1.radprof', format='ascii', header_start=2)\n",
    " d = Table.read('./data_full/PSZ2_G305.76+44.79/PSZ2_G305.76+44.79_vtp_1.radprof', format='ascii', header_start=2)\n",
    "\n",
    "#PSZ2_G028.08+10.79\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swift pixelscale in degrees\n",
    "pixsc =  6.548089E-04 * 3600\n",
    "x = (d['r1'] + d['r2'])/ 2. / 60. * pixsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the parameter fitting\n",
    "ndim = 4  # number of parameters in the model                                  \n",
    "nwalkers = 100  # number of MCMC walkers                                        \n",
    "nburn = 100  # \"burn-in\" period to let chains stabilize                        \n",
    "nsteps = 500  # number of MCMC steps to take  \n",
    "\n",
    "pos = [np.array([0.001, 1., 1., 0.001]) + 1e-4 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, prob, args=(x, d['sb'], d['sb_err']))\n",
    "sampler.run_mcmc(pos, nsteps)\n",
    "samples = sampler.get_chain(discard=nburn, thin=15, flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "So, rc, beta, bg = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(samples, [16, 50, 84],\n",
    "                                                axis=0)))\n",
    "print(So)\n",
    "print(rc)\n",
    "print(beta)\n",
    "print(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6.5, 5))\n",
    "# data\n",
    "ax.errorbar(x, d['sb'], yerr=d['sb_err'], fmt='o', label='data')\n",
    "for So, rc, beta, bg in samples[np.random.randint(len(samples), size=100)]:\n",
    "    ax.plot(x, beta_model(So, x, rc, beta) + bg, color='k', alpha=0.1)\n",
    "ylims = ax.get_ylim()\n",
    "\n",
    "#fit\n",
    "# So, rc, beta, bg = result['x']\n",
    "\n",
    "\n",
    "So, rc, beta, bg = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(samples, [16, 50, 84],\n",
    "                                                axis=0)))\n",
    "\n",
    "ax.plot(x, beta_model(So[0], x, rc[0], beta[0]) + bg[0], label=r'$\\beta$ + bg')\n",
    "ax.plot(x, beta_model(So[0], x, rc[0], beta[0]), label=r'$\\beta$')\n",
    "\n",
    "\n",
    "ax.axhline(bg[0], label='bg', zorder=0, lw=1)\n",
    "\n",
    "ax.text(rc[0] + 0.1, 2e-5, f\"rc = {rc[0]:.2f}'\", rotation='vertical', ha='left')\n",
    "ax.axvline(rc[0], zorder=0, lw=1)\n",
    "ax.semilogy()\n",
    "\n",
    "if ylims[0] < 1e-5:\n",
    "    ax.set_ylim(1e-5, ylims[1])\n",
    "else:\n",
    "    ax.set_ylim(ylims)\n",
    "ax.set_xlabel('Radius [arcmin]')\n",
    "ax.set_ylabel('Flux [cnts/s]')\n",
    "ax.legend(loc='upper right')\n",
    "#fig.savefig(f'/home/boada/PSZ1_G057.42-10.77_radproffit_2.png', bbox='tight', dpi=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[:,3] = np.log(samples[:,3])\n",
    "samples[:,0] = np.log(samples[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = corner.corner(samples, labels=['log So', 'rc', r'$\\beta$', 'log bg'],\n",
    "                    bins=[50, 50, 50, 50],\n",
    "                    smooth=True,\n",
    "                    fill_contours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = ['So', 'rc', 'beta', 'bg']\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
