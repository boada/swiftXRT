{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from glob import glob\n",
    "import shlex\n",
    "\n",
    "# parallel processor et al.\n",
    "from utilities import parallel_process, check_exe, system_call\n",
    "from utilities import get_immediate_subdirectories, redshifts_from_papers\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)\n",
    "from astropy import log\n",
    "log.setLevel('WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows us to run the pipeline not interactively. \n",
    "os.environ['HEADASNOQUERY'] = ''\n",
    "os.environ['HEADASPROMPT'] = '/dev/null'\n",
    "# os.environ['PFILES'] = '/tmp/$$.tmp/pfiles;$HEADAS/syspfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runnh(ra, dec):\n",
    "    '''This function will automatically run the ftool nh\n",
    "    on a given RA and Dec in J2000 equinox coordinates'''\n",
    "\n",
    "    nh = 0\n",
    "    cmd = f'nh equinox=2000 ra={ra} dec={dec}'\n",
    "    args = shlex.split(cmd)\n",
    "    out = \"\"\n",
    "\n",
    "    with subprocess.Popen(args,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          universal_newlines=True) as proc:\n",
    "\n",
    "        proc.wait()\n",
    "        out = proc.stdout.read()\n",
    "\n",
    "    outlines = out.split(\"\\n\")\n",
    "    for line in outlines:\n",
    "        if \"Weighted average\" in line:\n",
    "            nh = line.split(\" \")[-1]\n",
    "\n",
    "    return out, float(nh)\n",
    "\n",
    "def GetLuminosity(flux, distance):\n",
    "        #assumes distance is in mpc\n",
    "        #converts to cm\n",
    "        #returns L = (4piD^2)*f\n",
    "        distance = 3.86E24 * distance\n",
    "        return 4*math.pi*distance*distance*flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_beta_model(So, rc, beta, bkg):\n",
    "    ''' Solves for where (radius) the beta model is equal to the background\n",
    "\n",
    "    Make sure you keep track of the units going into all this. You wanna make \n",
    "    sure the radius comes out as something that makes sense.\n",
    "\n",
    "    '''\n",
    "\n",
    "    a = -3 * beta + 0.5\n",
    "\n",
    "    b = (bkg / So)**(1 / a) - 1\n",
    "\n",
    "    c = b * rc**2\n",
    "\n",
    "    return np.sqrt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bkg_regions(name, outpath):\n",
    "    ''' For each obs id we are going to create a background region. 10.5 arcmin\n",
    "    centered on the pointing position of each observation.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt',\n",
    "                 recursive=True)\n",
    "\n",
    "    if len(files) < 1:\n",
    "        return\n",
    "\n",
    "    # create a place for the products\n",
    "    if not os.path.isdir(f'{outpath}/{name}/spec_files'):\n",
    "        os.makedirs(f'{outpath}/{name}/spec_files')\n",
    "\n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "\n",
    "        # get pointing\n",
    "        point_ra = fits.getheader(f_in, ext=0)['RA_PNT']\n",
    "        point_dec = fits.getheader(f_in, ext=0)['DEC_PNT']\n",
    "\n",
    "        # we cannot use the X/Y position in the catalog because it was detected \n",
    "        # in the combined frame. We need to use the RA/DEC and then find the \n",
    "        # pixel positions in the individual frames. Lame.\n",
    "        # WCS info to convert world coords to pixels\n",
    "        hdr = fits.getheader(f_in.replace('cl.evt', 'ex.img'))\n",
    "        w = wcs.WCS(hdr)\n",
    "        pixels = w.wcs_world2pix(point_ra, point_dec, 0)\n",
    "\n",
    "        obs_id = f_in.split('/')[-2]\n",
    "\n",
    "        # write out the regions\n",
    "        with open(f'{outpath}/{name}/spec_files/{obs_id}_bkg.reg', 'w') as reg:\n",
    "            # write the background region -- different sizes for different types of obs.\n",
    "            if f_in[-10] == '3':\n",
    "                reg.write(\n",
    "                    f\"circle({pixels[0]:.5f},{pixels[1]:.5f},{(11 * 60 /2.36):.5f})\\n\"\n",
    "                )\n",
    "            else:\n",
    "                reg.write(\n",
    "                    f\"circle({pixels[0]:.5f},{pixels[1]:.5f},{(9.5 * 60 /2.36):.5f})\\n\"\n",
    "                )\n",
    "\n",
    "            for j, xc, yc, rc, rotc in detects[[\n",
    "                    'INDEX', 'RA', 'DEC', 'R', 'ROTANG'\n",
    "            ]]:\n",
    "                pixels = w.wcs_world2pix(xc, yc, 0)\n",
    "                reg.write(f'-ellipse({pixels[0]:.5f},{pixels[1]:.5f},{rc[0]:.3f}'\n",
    "                          f',{rc[1]:.3f},{rotc:.3f})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_src_regions(name, outpath):\n",
    "    ''' For each obs id we are going to create a background region. 10.5 arcmin\n",
    "    centered on the pointing position of each observation.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt',\n",
    "                 recursive=True)\n",
    "\n",
    "    if len(files) < 1:\n",
    "        return\n",
    "\n",
    "    # create a place for the products\n",
    "    if not os.path.isdir(f'{outpath}/{name}/spec_files'):\n",
    "        os.makedirs(f'{outpath}/{name}/spec_files')\n",
    "\n",
    "    # get the MCMC fits:\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_mcmcfits.txt'):\n",
    "        mcmcfit = Table.read(f'{outpath}/{name}/{name}_mcmcfits.txt',\n",
    "                             format='ascii',\n",
    "                             header_start=0)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_mcmcfits.txt')\n",
    "\n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "\n",
    "        obs_id = f_in.split('/')[-2]\n",
    "\n",
    "        # we cannot use the X/Y position in the catalog because it was detected \n",
    "        # in the combined frame. We need to use the RA/DEC and then find the \n",
    "        # pixel positions in the individual frames. Lame.\n",
    "        # WCS info to convert world coords to pixels\n",
    "        hdr = fits.getheader(f_in.replace('cl.evt', 'ex.img'))\n",
    "        w = wcs.WCS(hdr)\n",
    "\n",
    "        # now we have to loop through the detections\n",
    "        for j, xc, yc, ext in detects[['INDEX', 'RA', 'DEC', 'Extended']]:\n",
    "\n",
    "            # we didn't fit all the sources with the MCMC\n",
    "            if j not in mcmcfit['ID']:\n",
    "                continue\n",
    "            elif ext < 1:\n",
    "                continue\n",
    "                \n",
    "            # write out the regions\n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg',\n",
    "                      'w') as reg:\n",
    "                # Here we are going to draw a circle with a radius where the beta \n",
    "                # model just fades into the background. These values come from \n",
    "                # the MCMC fits done previously.\n",
    "                radius = inv_beta_model(mcmcfit['So_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['rc_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['beta_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['bg_50'][mcmcfit['ID'] == j])\n",
    "\n",
    "                pixels = w.wcs_world2pix(xc, yc, 0)\n",
    "\n",
    "                reg.write(\n",
    "                    f\"circle({pixels[0]},{pixels[1]},{(radius[0] * 60 / 2.36):.3f})\\n\"\n",
    "                )\n",
    "\n",
    "                # have to loop through them again for the masks\n",
    "                for k, xc2, yc2, rc, rotc in detects[[\n",
    "                        'INDEX', 'RA', 'DEC', 'R', 'ROTANG'\n",
    "                ]]:\n",
    "                    if not j == k:\n",
    "                        pixels = w.wcs_world2pix(xc2, yc2, 0)\n",
    "                        reg.write(f'-ellipse({pixels[0]:.5f},{pixels[1]:.5f},'\n",
    "                                  f'{rc[0]:.3f},{rc[1]:.3f},{rotc:.3f})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xselect_pha(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt',\n",
    "                 recursive=True)\n",
    "\n",
    "    if len(files) < 1:\n",
    "        return\n",
    "\n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "\n",
    "        obs_id = f_in.split('/')[-2]\n",
    "\n",
    "        # create the background xselect call first\n",
    "        if not os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_bkg.reg'):\n",
    "            continue\n",
    "\n",
    "        # write background xsel.in\n",
    "        with open(f'{outpath}/{name}/spec_files/{obs_id}_bkg.in', 'w') as f:\n",
    "            # this is the session name... specify random letters to run many at once.\n",
    "            f.writelines(f'{obs_id}\\n')\n",
    "            f.writelines('read events\\n')\n",
    "            # set the data directory\n",
    "            f.writelines('/'.join(f_in.split('/')[:5]) + '\\n')\n",
    "            # first entry\n",
    "            f.writelines('/'.join(f_in.split('/')[5:]) + '\\n')\n",
    "            f.writelines('yes\\n')\n",
    "            f.writelines(\n",
    "                f'filter region {outpath}/{name}/spec_files/{obs_id}_bkg.reg\\n'\n",
    "            )\n",
    "            f.writelines('extract spectrum\\n')\n",
    "            f.writelines(\n",
    "                f'save spectrum {outpath}/{name}/spec_files/{obs_id}_bkg_pc.pha\\n'\n",
    "            )\n",
    "            if os.path.isfile(\n",
    "                    f'{outpath}/{name}/spec_files/{obs_id}_bkg_pc.pha'):\n",
    "                f.writelines('yes\\n')\n",
    "            f.writelines('exit\\n')\n",
    "            f.writelines('no\\n')\n",
    "\n",
    "        # call\n",
    "#         stdout, stderr = system_call(f'xselect @{outpath}/{name}/spec_files/{obs_id}_bkg.in')\n",
    "\n",
    "#         # log the output\n",
    "        log_file = f'{outpath}/{name}/spec_files/{obs_id}_bkg_pha.log'\n",
    "#         with open(log_file, 'w') as f:\n",
    "#             f.writelines(stdout)\n",
    "\n",
    "        os.system(f'xselect @{outpath}/{name}/spec_files/{obs_id}_bkg.in > {log_file}')    \n",
    "            \n",
    "            \n",
    "        # now we do all the sources.\n",
    "        for j in detects['INDEX']:\n",
    "            if not os.path.isfile(\n",
    "                    f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg'):\n",
    "                continue\n",
    "\n",
    "            # write source xsel.in\n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}.in',\n",
    "                      'w') as f:\n",
    "                # this is the session name... specify random letters to run many at once.\n",
    "                f.writelines(f'{obs_id}_{j}\\n')\n",
    "                f.writelines('read events\\n')\n",
    "                # set the data directory\n",
    "                f.writelines('/'.join(f_in.split('/')[:5]) + '\\n')\n",
    "                # first entry\n",
    "                f.writelines('/'.join(f_in.split('/')[5:]) + '\\n')\n",
    "                f.writelines('yes\\n')\n",
    "                f.writelines(\n",
    "                    f'filter region {outpath}/{name}/spec_files/{obs_id}_{j}.reg\\n'\n",
    "                )\n",
    "                f.writelines('extract spectrum\\n')\n",
    "                f.writelines(\n",
    "                    f'save spectrum {outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha\\n'\n",
    "                )\n",
    "                if os.path.isfile(\n",
    "                        f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'):\n",
    "                    f.writelines('yes\\n')\n",
    "                f.writelines('exit\\n')\n",
    "                f.writelines('no\\n')            \n",
    "            \n",
    "#             # call\n",
    "#             stdout, stderr = system_call(f'xselect @{outpath}/{name}/spec_files/{obs_id}_{j}.in')\n",
    "            \n",
    "#             # log the output\n",
    "            log_file = f'{outpath}/{name}/spec_files/{obs_id}_{j}_pha.log'\n",
    "#             with open(log_file, 'w') as f:\n",
    "#                 f.writelines(stdout)\n",
    "                \n",
    "            os.system(f'xselect @{outpath}/{name}/spec_files/{obs_id}_{j}.in > {log_file}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_arf(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/**xpcw[1-4]po_ex.img',\n",
    "                 recursive=True)\n",
    "\n",
    "    if len(files) < 1:\n",
    "        return\n",
    "\n",
    "    check_exe('xrtmkarf')\n",
    "\n",
    "    for f_in in files:\n",
    "\n",
    "        obs_id = f_in.split('/')[-2]\n",
    "        # now we have to loop through the detections\n",
    "        for j, ra, dec in detects[['INDEX', 'RA', 'DEC']]:\n",
    "            # check that we have the files\n",
    "            if not os.path.isfile(\n",
    "                    f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'):\n",
    "                continue\n",
    "            else:\n",
    "                pha = f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'\n",
    "\n",
    "                \n",
    "            # check to make sure the spectrum has counts    \n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pha.log') as logfile:\n",
    "                outlines = logfile.readlines()\n",
    "                for line in outlines:\n",
    "                    line = \" \".join(line.split())\n",
    "                    if \"Spectrum has\" in line:\n",
    "                        counts = int(line.split()[2])\n",
    "                        break\n",
    "\n",
    "            if not counts > 0:\n",
    "                continue\n",
    "                \n",
    "            # we cannot use the X/Y position in the catalog because it was \n",
    "            # detected in the combined frame. We need to use the RA/DEC and then\n",
    "            # find the pixel positions in the individual frames. Lame.\n",
    "            # WCS info to convert world coords to pixels\n",
    "            hdr = fits.getheader(f_in)\n",
    "            w = wcs.WCS(hdr)\n",
    "            pixels = w.wcs_world2pix(ra, dec, 0)\n",
    "\n",
    "            cmd = (f'xrtmkarf phafile={pha} srcx={pixels[0]} srcy={pixels[1]} '\n",
    "                   f'outfile={outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf '\n",
    "                   f'psfflag=yes extended=yes expofile={f_in} clobber+')\n",
    "\n",
    "#             # call\n",
    "#             stdout, stderr = system_call(cmd)\n",
    "            \n",
    "#             # log the output\n",
    "            log_file = f'{outpath}/{name}/spec_files/{obs_id}_{j}_arf.log'\n",
    "#             with open(log_file, 'w') as f:\n",
    "#                 f.writelines(stdout)\n",
    "\n",
    "            os.system(f'{cmd} > {log_file}')    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_spectra(name, outpath, cnts=10):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # get a list of the reduced obs.\n",
    "    reduc = get_immediate_subdirectories(f'{outpath}/{name}/reduced')\n",
    "    reduc_ids = [r.split('/')[-1] for r in reduc]\n",
    "\n",
    "    if len(reduc) < 1:\n",
    "        return\n",
    "\n",
    "    check_exe('addascaspec')\n",
    "    # we are gonna need to change directories\n",
    "    wd = os.getcwd()\n",
    "\n",
    "    # now we do all the sources.\n",
    "    for j, ext in detects[['INDEX', 'Extended']]:\n",
    "\n",
    "        if ext < 1:\n",
    "            continue\n",
    "        \n",
    "        # remove files if they are already there.\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc.pha'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_pc.pha')\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc.arf'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_pc.arf')\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_bkg.pha'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_bkg.pha')\n",
    "        \n",
    "        good_reduc_ids = [obs_id for obs_id in reduc_ids \n",
    "                         if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg')]\n",
    "\n",
    "        # build the file lists:\n",
    "        spectra = [f'{obs_id}_{j}_pc.pha' for obs_id in good_reduc_ids\n",
    "                  if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf')]\n",
    "        bkgs = [f'{obs_id}_bkg_pc.pha' for obs_id in good_reduc_ids\n",
    "               if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf')]\n",
    "        arfs = [f'{obs_id}_{j}_pc.arf' for obs_id in good_reduc_ids\n",
    "               if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf')]\n",
    "\n",
    "        # the rmfs are harder to build\n",
    "        rmfs = []\n",
    "        for obs_id in good_reduc_ids:\n",
    "            if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf'):\n",
    "                with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}_arf.log',\n",
    "                          'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for l in lines:\n",
    "                        # DO NOT REMOVE THE DOUBLE SLASH!!!\n",
    "                        if '/opt/caldb//data/swift/xrt/cpf/rmf/' in l:\n",
    "                            rmfs.append(l.split(\"'\")[1])\n",
    "\n",
    "        if len(spectra) > 0:\n",
    "        \n",
    "            # have to write the file list to pass to the spectrum combiner.\n",
    "            with open(f'{outpath}/{name}/spec_files/{j}.list', 'w') as f:\n",
    "                f.writelines(f'{\" \".join(spectra[:30])}\\n')\n",
    "                f.writelines(f'{\" \".join(bkgs[:30])}\\n')\n",
    "                f.writelines(f'{\" \".join(arfs[:30])}\\n')\n",
    "                f.writelines(f'{\" \".join(rmfs[:30])}\\n')\n",
    "\n",
    "            # log the output\n",
    "            log_file = f'{j}_addascaspec.log'\n",
    "\n",
    "            cmd = f'addascaspec {j}.list {j}_pc.pha {j}_pc.arf {j}_bkg.pha'\n",
    "\n",
    "            # call\n",
    "            os.chdir(f'{outpath}/{name}/spec_files')\n",
    "#             stdout, stderr = system_call(cmd)                   \n",
    "                             \n",
    "#             # log\n",
    "            log_file = f'{j}_addascaspec.log'\n",
    "#             with open(log_file, 'w') as f:\n",
    "#                 f.writelines(stdout)\n",
    "\n",
    "            os.system(f'{cmd} > {log_file}')    \n",
    "                \n",
    "        # group the counts\n",
    "        cmd = (f\"grppha infile='{j}_pc.pha' outfile='{j}_pc_{cnts}cts.pha' \"\n",
    "               f\"chatter=0 comm='bad 1-31 & group min {cnts} & exit' clob+\")\n",
    "        \n",
    "        if os.path.isfile(f'{j}_pc.pha'):                 \n",
    "                         \n",
    "#             # call\n",
    "#             stdout, stderr = system_call(cmd)                   \n",
    "\n",
    "#             # log\n",
    "            log_file = f'{j}_grppha.log'\n",
    "#             with open(log_file, 'w') as f:\n",
    "#                 f.writelines(stdout)\n",
    "            \n",
    "            os.system(f'{cmd} > {log_file}')\n",
    "            \n",
    "            \n",
    "        os.chdir(wd)\n",
    "    os.chdir(wd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_xspec_scripts(name, outpath, kT=5, z=0.1, cnts=10):\n",
    "\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    if not z > 0:\n",
    "        z = 0.1\n",
    "        \n",
    "    # now we have to loop through the detections\n",
    "    for j, ra, dec in detects[['INDEX', 'RA', 'DEC']]:\n",
    "        if not os.path.isfile(\n",
    "                f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts.pha'):\n",
    "            continue\n",
    "        else:\n",
    "            source_10cts_pha_name = f'{j}_pc_{cnts}cts.pha'\n",
    "\n",
    "        # get our nH value\n",
    "        nH = runnh(ra, dec)[1]\n",
    "\n",
    "        # here is the text we are going to write\n",
    "        text = [\n",
    "            \"statistic chi\\n\",\n",
    "            f\"data 1:1 {outpath}/{name}/spec_files/{source_10cts_pha_name}\\n\",\n",
    "            f'{outpath}/{name}/spec_files/{j}_pc.arf\\n',\n",
    "            f'{outpath}/{name}/spec_files/{j}_bkg.pha\\n',\n",
    "            \"ignore bad\\n\",\n",
    "            \"ignore 1\\n\",\n",
    "            'method leven 10 0.01\\n',\n",
    "            'abund angr\\n',\n",
    "            'xsect bcmc\\n',\n",
    "            'cosmo 70 0 0.70\\n',\n",
    "            'systematic 0\\n',\n",
    "            \"model  phabs*mekal\\n\",\n",
    "            f\"\\t{nH/1e22}, -1\\n\",\n",
    "            f\"\\t{kT}, -1\\n\",\n",
    "            \"\\t1\\n\",\n",
    "            \"\\t0.3\\n\",\n",
    "            f\"\\t{z}\\n\",\n",
    "            \"\\t1\\n\",\n",
    "            \"\\t0\\n\",\n",
    "            \"fit\\n\",\n",
    "            f'cpd {outpath}/{name}/spec_files/{j}_pc_{cnts}cts.ps/cps\\n',\n",
    "            'setplot energy\\n',\n",
    "            'plot ldata\\n',\n",
    "            'cpd none\\n',\n",
    "            \"error 1.0 7\\n\",\n",
    "            \"newpar 1 0\\n\",\n",
    "#             \"flux 0.1 2.4\\n\",\n",
    "            \"flux 0.5 2\\n\",\n",
    "            f\"lum 0.5 2.0 {z}\\n\",\n",
    "#             \"flux 2 10\\n\",\n",
    "            f\"data 1:1 {outpath}/{name}/spec_files/{j}_pc.pha\\n\",\n",
    "            f'{outpath}/{name}/spec_files/{j}_pc.arf\\n',\n",
    "            f'{outpath}/{name}/spec_files/{j}_bkg.pha\\n',\n",
    "            \"ignore bad\\n\",\n",
    "            \"ignore **-0.5,2.0-**\\n\",\n",
    "            \"show rates\\n\",\n",
    "            \"exit\\n\"\n",
    "        ]\n",
    "\n",
    "        #Write it to the script\n",
    "        with open(f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts_xspec.in',\n",
    "                  'w') as script:\n",
    "            for line in text:\n",
    "                script.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xspec_scripts(name, outpath, cnts=10):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        return\n",
    "#         raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    results = {}\n",
    "    results['field'] = name\n",
    "    \n",
    "    # now we have to loop through the detections\n",
    "    for j in detects['INDEX']:\n",
    "        if not os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts_xspec.in'):\n",
    "            continue\n",
    "        else:\n",
    "            source_xspec_in = f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts_xspec.in'\n",
    "\n",
    "        # individual source result\n",
    "        results[j] = {}    \n",
    "            \n",
    "        # build the command and call it\n",
    "        cmd = f\"xspec < {source_xspec_in}\"\n",
    "        stdout, stderr = system_call(cmd, shlexify=False)\n",
    "                \n",
    "        # log\n",
    "        log_file = f'{outpath}/{name}/spec_files/{j}_xspec.log'\n",
    "        with open(log_file, 'w') as f:\n",
    "            f.writelines(stdout)\n",
    "        \n",
    "        #Read the fluxes and norms from the stdout\n",
    "        photon_flux = {}\n",
    "        energy_flux = {}\n",
    "        cnt_rate = {}\n",
    "        norms = []\n",
    "        chi2 = -1\n",
    "        lum = -1\n",
    "        \n",
    "        count = 1\n",
    "        \n",
    "        outlines = stdout.split('\\n')\n",
    "        for line in outlines:\n",
    "            if \"Model Flux\" in line:\n",
    "                line = line.replace('  ', ' ')\n",
    "                band_low = float(line.split(\" \")[8].split(\"(\")[1])\n",
    "                band_high = float(line.split(\" \")[10])\n",
    "                photons = float(line.split(\" \")[3])\n",
    "                band = f'{band_low:.1f}-{band_high:.1f}' \n",
    "                photon_flux[band] = photons\n",
    "\n",
    "                energy = float(line.split(\" \")[5].split(\"(\")[1])\n",
    "                energy_flux[band] = energy\n",
    "            elif \"2\" in line and \"mekal\" in line and \"norm\" in line:\n",
    "                #the norm will be two index before the +/- sign\n",
    "                pm_index = line.split(\" \").index(\"+/-\")\n",
    "                norms.append(line.split(\" \")[pm_index - 2])\n",
    "\n",
    "            elif \"Net count rate\" in line:\n",
    "                cnt_rate['Net'] = line.split(' ')[7]\n",
    "\n",
    "            elif \"Model predicted rate\" in line:\n",
    "                cnt_rate['Model'] = float(line.split(' ')[4])\n",
    "            elif \"Reduced chi-squared\" in line and count <= 2:\n",
    "                chi2 = line.split()[3]\n",
    "                count += 1\n",
    "            elif \"Model Luminosity\" in line:\n",
    "                lum = float(line.split()[2])\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            #Assuming the current script format, this is the one we want\n",
    "            #This is with PE Absorption\n",
    "            goodnorm = float(norms[1])\n",
    "            \n",
    "            #Get the index of the line containing the sigmas\n",
    "            conf_index = outlines.index(\n",
    "                \" Parameter   Confidence Range (1)\")\n",
    "            sigma_line = outlines[conf_index + 1]\n",
    "            sigma_low = float(\n",
    "                sigma_line.split(\" \")[-1].split(\"(\")[1].split(\",\")[0])\n",
    "            sigma_high = float(\n",
    "                sigma_line.split(\" \")[-1].split(\"(\")[1].split(\",\")\n",
    "                [1].split(\")\")[0])\n",
    "            sigma_av = (abs(sigma_low) + abs(sigma_high)) / 2\n",
    "\n",
    "            SN = goodnorm / sigma_av\n",
    "        except (ValueError, IndexError):\n",
    "            SN = -1\n",
    "        \n",
    "        results[j]['SN'] = SN\n",
    "        results[j]['Chi2'] = chi2\n",
    "        results[j]['flux'] = energy_flux\n",
    "        results[j]['cnt_rate'] = cnt_rate\n",
    "\n",
    "            # Luminosity\n",
    "            try:\n",
    "                lum = results[indx]['Lum']\n",
    "                f.write(f'{lum} ')\n",
    "            except KeyError: # no luminosity\n",
    "                lum = -1\n",
    "                f.write(f'{lum} ')    \n",
    " \n",
    "            f.write('\\n')\n",
    "\n",
    "#     print(results)    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_values('NAME')\n",
    "\n",
    "data = redshifts_from_papers(data)\n",
    "\n",
    "outpath = './data_full_new'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "parallel_process(arr, create_bkg_regions, use_kwargs=True, n_jobs=6)\n",
    "parallel_process(arr, create_src_regions, use_kwargs=True, n_jobs=6)\n",
    "parallel_process(arr, xselect_pha, use_kwargs=True, n_jobs=6) # 1.5 hours\n",
    "parallel_process(arr, mk_arf, use_kwargs=True, n_jobs=6) # 50 minutes\n",
    "parallel_process(arr, combine_spectra, use_kwargs=True, n_jobs=1)\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath, 'z':z} for n, z in zip(data['NAME'], data['REDSHIFT'])]\n",
    "parallel_process(arr, mk_xspec_scripts, use_kwargs=True, n_jobs=6)\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "results = parallel_process(arr, run_xspec_scripts, use_kwargs=True, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For testing ###\n",
    "\n",
    "\n",
    "outpath ='./data_full'\n",
    "name = 'PSZ2_G075.08+19.83'\n",
    "# name = 'PSZ2_G139.62+24.18'\n",
    "# name = 'PSZ1_G121.35-42.47'\n",
    "# name = 'PSZ2_G057.80+88.00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bkg_regions(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_src_regions(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xselect_pha(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mk_arf(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_spectra(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_xspec_scripts(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_xspec_scripts(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
