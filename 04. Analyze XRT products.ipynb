{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.table import Table\n",
    "from tqdm import tqdm_notebook\n",
    "import tempfile\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add extra code to run things in parallel.\n",
    "The combining exposure maps takes a REALLY long time. So I added this bit so I can run it all in parallel.\n",
    "\n",
    "You don't need to run any of this if you don't want to run things in paralle. I'll try to comment out code at the bottom so you can run things in parallel or not depending on what you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_process(array, function, n_jobs=None, use_kwargs=False, front_num=0):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the \n",
    "                parallel job. This can be useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    #We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "    #If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        [function(**a) if use_kwargs else function(a) for a in tqdm_notebook(array[front_num:])]\n",
    "        return \n",
    "    #Assemble the workers\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        #Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': False,\n",
    "            'leave': True\n",
    "        }\n",
    "        #Print out the progress as tasks complete\n",
    "        for f in tqdm_notebook(as_completed(futures), **kwargs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_detect(name, outpath, pp=None):\n",
    "    ''' This uses the detect function as part of the ximage package. This tool was originally\n",
    "    written to work with SWIFT data. Because SWIFT was really designed to be a point source\n",
    "    observatory, this tool is pretty good at finding point sources. \n",
    "    \n",
    "    I think we have replaced this function with the second detect function, below, which uses\n",
    "    a different tool, originally written to find extended sources in CHANDRA data. That seems \n",
    "    to be more of what we are trying to do, and it seems to have a similar performance.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(f'{outpath}/{name}/{name}_ximg_det.in', 'w') as f:\n",
    "        for eng in [200, 300, 400, 500, 600]:\n",
    "            if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}.fits'):\n",
    "                continue\n",
    "            f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl4.fits\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'fitsdet={{{outpath}/{name}/{name}_img_50-{eng}_bl4.det.fits}}\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'filedet={{{outpath}/{name}/{name}_img_50-{eng}_bl4.det}}\\n')\n",
    "            \n",
    "            f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl8.fits\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'fitsdet={{{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits}}\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'filedet={{{outpath}/{name}/{name}_img_50-{eng}_bl8.det}}\\n')\n",
    "            \n",
    "            # remove old files if they exist\n",
    "            if os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits'):\n",
    "                os.remove(f'{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits')\n",
    "                \n",
    "        f.writelines('exit\\n')\n",
    "\n",
    "    # log output\n",
    "    log_file = f'{outpath}/{name}/{name}_ximg_det.log'\n",
    "        \n",
    "    # call xselect\n",
    "    cmd = f'ximage < {outpath}/{name}/{name}_ximg_det.in > {log_file}'\n",
    "    if not pp:\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        pp.submit(call_cmd, cmd)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vtp(name, outpath, pp=None):\n",
    "    # set up all the non-file-specific parameters\n",
    "    params = {}\n",
    "    params['scale'] = 1\n",
    "    params['limit'] = 1E-6\n",
    "    params['coarse'] = 5\n",
    "    params['maxiter'] = 10\n",
    "    params['regfile'] = f'{outpath}/{name}/{name}_vtp.reg'\n",
    "    params['log'] = f'{outpath}/{name}/{name}_vtp.log'\n",
    "    params['clobber'] = 'yes'\n",
    "    params['verbose'] = 1\n",
    "    \n",
    "    evts = f'{outpath}/{name}/{name}_events.fits'\n",
    "    expmap = f'{outpath}/{name}/{name}_exp.fits'\n",
    "    outfits = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "    \n",
    "    # check to make sure the files exist.\n",
    "    if not os.path.isfile(evts) and not os.path.isfile(expmap):\n",
    "        return 0\n",
    "    \n",
    "    with open(f'{outpath}/{name}/{name}_vtp.in', 'w') as f:\n",
    "        # build the cmd\n",
    "        cmd = f'vtpdetect {evts}[pi=50:600] {expmap} {outfits} '\n",
    "        for param, value in list(params.items()):                                    \n",
    "            cmd += f'{param}={value} '\n",
    "        f.writelines(f'{cmd}\\n')\n",
    "    \n",
    "    os.system(cmd)\n",
    "    \n",
    "    return name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf(name, outpath, pp=None):\n",
    "    \n",
    "    with open(f'{outpath}/{name}/{name}_ximg_psf.in', 'w') as f:\n",
    "        # loop over the blocked images\n",
    "        for blk in [4, 8]:\n",
    "            # loop over the energies\n",
    "            for eng in [200, 300, 400, 500, 600]:\n",
    "                if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det'):\n",
    "                    continue\n",
    "\n",
    "                # figure out the background level\n",
    "                with open(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det', 'r') as f2:\n",
    "                    for l in f2.readlines():\n",
    "                        if 'Back' in l:\n",
    "                            background = float(l.split(':')[-1])\n",
    "                            break\n",
    "\n",
    "                # read the image\n",
    "                f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl{blk}.fits\\n')\n",
    "\n",
    "                # now we need to read the individual detections\n",
    "                detects = Table.read(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det.fits')\n",
    "\n",
    "                # write psf commands for each detection\n",
    "                for i, (x, y) in enumerate(detects[['X', 'Y']]):\n",
    "                    f.writelines(f'psf/xpix={x}/ypix={y}/back={background}/radius=4.25/noplot/'\n",
    "                                f'fileplot={{{outpath}/{name}/{name}_img_50-{eng}_bl{blk}_{i}.psf}}\\n')\n",
    "\n",
    "                    \n",
    "        f.writelines('exit\\n')\n",
    "\n",
    "    # log output\n",
    "    log_file = f'{outpath}/{name}/{name}_ximg_psf.log'\n",
    "        \n",
    "    # call xselect\n",
    "    cmd = f'ximage < {outpath}/{name}/{name}_ximg_psf.in > {log_file}'\n",
    "    \n",
    "    os.system(cmd)\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(name, outpath, pp=None):\n",
    "    \n",
    "        # loop over the blocked images\n",
    "        for blk in [4, 8]:\n",
    "            # loop over the energies\n",
    "            for eng in [200, 300, 400, 500, 600]:\n",
    "                if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det'):\n",
    "                    continue\n",
    "\n",
    "                # figure out the background level\n",
    "                with open(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det', 'r') as f2:\n",
    "                    for l in f2.readlines():\n",
    "                        if 'Back' in l:\n",
    "                            background = float(l.split(':')[-1])\n",
    "                            break\n",
    "\n",
    "                # now we need to read the individual detections\n",
    "                detects = Table.read(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det.fits')\n",
    "                \n",
    "                # write psf commands for each detection\n",
    "                for i, (ra, dec) in enumerate(detects[['RA', 'DEC']]):\n",
    "                    with open(f'{outpath}/{name}/{name}_cent_50-{eng}_bl{blk}_{i}.in', 'w') as f:\n",
    "                        cmd = 'xrtcentroid '\n",
    "                        cmd += f'infile={outpath}/{name}/{name}_img_50-{eng}_bl{blk}.fits '\n",
    "                        cmd += f'outfile={name}_img_50-{eng}_bl{blk}_{i}.cent '\n",
    "                        cmd += f'outdir={outpath}/{name} '\n",
    "                        cmd += f'boxra={ra} '\n",
    "                        cmd += f'boxdec={dec} '\n",
    "                        cmd += 'calcpos=yes ' \n",
    "                        cmd += 'interactive=no '\n",
    "                        cmd += 'boxradius=1 '\n",
    "                        cmd += 'clobber=yes'\n",
    "\n",
    "                        f.writelines(cmd)\n",
    "                        \n",
    "                    # log output\n",
    "                    log_file = f'{outpath}/{name}/{name}_cent_50-{eng}_bl{blk}_{i}.log'\n",
    "        \n",
    "                    # call xselect\n",
    "                    cmd = f'{cmd} > {log_file}'\n",
    "                    \n",
    "                    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radprof(name, outpath, overwrite=False):\n",
    "    # Swift XRT pixel scale\n",
    "    # 1 pixel = 6.548089E-04 * 3600 arcsec\n",
    "    pixscale = 6.548089E-04 * 3600\n",
    "    \n",
    "    # model parameters\n",
    "    params = {}\n",
    "    params['n'] = 75\n",
    "    params['r0'] = 0 \n",
    "    params['dr'] = 4\n",
    "    \n",
    "    # check for files\n",
    "    # events image\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200.fits'):\n",
    "        return\n",
    "    else:\n",
    "        evnts = f'{outpath}/{name}/{name}_img_50-200.fits'\n",
    "    # expo map\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_exp.fits'):\n",
    "        return\n",
    "    else:\n",
    "        expmap = f'{outpath}/{name}/{name}_exp.fits'   \n",
    "    # detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "    \n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "    \n",
    "    # we are going to compute profiles for the 10 biggest -- this is for speed. \n",
    "    detects.sort(['SRC_AREA'], reverse=True)\n",
    "    \n",
    "    # loop over the sources -- component is the source ID number\n",
    "    for i, xc, yc in detects[['COMPONENT', 'X', 'Y']][:10]:\n",
    "        # decide whether we need to redo the profile\n",
    "        if overwrite:\n",
    "            pass\n",
    "        elif os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}.radprof'):\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # output file\n",
    "        with open(f'{outpath}/{name}/{name}_vtp_{i-1}.radprof', 'w') as radprof:\n",
    "            radprof.write(f\"# source number and position: {name}_{i} {xc:.3f} {yc:.3f}\\n\")\n",
    "            radprof.write(f\"# profile parameters: {params['n']} {params['r0']} {params['dr']}\\n\")\n",
    "            radprof.write(f\"# bin r1 r2 x y w sb sb_err\\n\")\n",
    "\n",
    "            fd2, path2 = tempfile.mkstemp() # this is the temp file to store the awk output\n",
    "            for irad in range(params['n']):\n",
    "                r1 = params['r0'] + irad * params['dr']\n",
    "                r2 = params['r0'] + (irad + 1) * params['dr']\n",
    "\n",
    "                fd, path = tempfile.mkstemp()\n",
    "                with os.fdopen(fd, 'w') as reg:\n",
    "                    reg.write(\"# Region file format: CIAO version 1.0\\n\")\n",
    "                    reg.write(f\"+annulus({xc},{yc},{r1},{r2})\\n\")\n",
    "                    for j, xc1, yc1, rc, rotc in detects[['COMPONENT', 'X', 'Y', 'R', 'ROTANG']]:\n",
    "                        if not j == i:\n",
    "                            reg.write(f\"-ellipse({xc1},{yc1},{rc[0]},{rc[1]},{rotc})\\n\")\n",
    "                          \n",
    "                #  No. of counts from data image\n",
    "                cmd = f\"dmstat '{evnts}[(x,y)=region({path})]' centroid- | grep sum | awk '{{print $2}}' > {path2}\"\n",
    "                #print(cmd)\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    x = tmp.readlines()[0][:-1]\n",
    "                x = float(x)\n",
    "\n",
    "                #  Mean exposure\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep mean | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    y = tmp.readlines()[0][:-1]\n",
    "                y = float(y)\n",
    "\n",
    "                #  No. of pixels\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep good | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    w = tmp.readlines()[0][:-1]\n",
    "                w = float(w)\n",
    "\n",
    "                os.remove(path)\n",
    "            \n",
    "                sb = x / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                err_gehrels = sqrt(x + 0.75)\n",
    "                sbe = (1. + err_gehrels) / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "\n",
    "                radprof.write(f\"{irad+1:3d} {r1:7d} {r2:7d} {x:9.1f} {y:9.1f} {w:9.1f} {sb:12.4e} {sbe:12.4e}\\n\")\n",
    "            os.remove(path2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PSZcatalog():\n",
    "    from astropy.table import Table                                                       \n",
    "    from numpy import append as npappend                                             \n",
    "\n",
    "    datapath = './../planckClusters/catalogs/'\n",
    "    \n",
    "    ps1 = Table.read(f'{datapath}/PSZ1v2.1.fits')\n",
    "    ps2 = Table.read(f'{datapath}/PSZ2v1.fits')\n",
    "\n",
    "    # convert to pandas\n",
    "    df1 = ps1.to_pandas()\n",
    "    df2 = ps2.to_pandas()\n",
    "\n",
    "    # clean up strings -- not required\n",
    "    df1 = df1.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "    df2 = df2.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "\n",
    "    # merge the catalogs together\n",
    "    df_m = df1.merge(df2, how='outer', left_on='INDEX', right_on='PSZ', suffixes=('_PSZ1', '_PSZ2'))\n",
    "    \n",
    "    # get the columns that we want\n",
    "    cols = df_m.columns[[0, 1, 4, 5, 8, 29, 33, 34, 37, 38, 40, 51]]\n",
    "    df_final = df_m[cols]\n",
    "\n",
    "    # remerge to find bits that were missing                                        \n",
    "    df_final_bigger = df_final.merge(df2, how='left', left_on='INDEX_PSZ1',         \n",
    "                                 right_on='PSZ')\n",
    "    # fill in nans                                                                  \n",
    "    for col in ['NAME', 'RA', 'DEC', 'SNR', 'REDSHIFT', 'INDEX']:                   \n",
    "        df_final_bigger[col+'_PSZ2'] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col])\n",
    "    # fill in nans                                                                  \n",
    "    for col in ['NAME', 'RA', 'DEC', 'SNR', 'REDSHIFT', 'INDEX']:\n",
    "        df_final_bigger[col+'_PSZ2'] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col])\n",
    "    for col in ['NAME', 'RA', 'DEC']:\n",
    "        df_final_bigger[col] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col+'_PSZ1'])\n",
    "\n",
    "    df_final_bigger = df_final_bigger[npappend(df_final_bigger.columns[:12].values, ['NAME', 'RA', 'DEC'])]\n",
    "\n",
    "    return df_final_bigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'erg/s/cm2' contains multiple slashes, which is discouraged by the FITS standard [astropy.units.format.generic]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9c14cba6f34ae2b2efa46561c92024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1943), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'count/s/pixel' contains multiple slashes, which is discouraged by the FITS standard [astropy.units.format.generic]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath, 'overwrite':True} for n in data['NAME']]\n",
    "#parallel_process(arr, source_detect, use_kwargs=True)\n",
    "#parallel_process(arr, detect_vtp, use_kwargs=True)\n",
    "#parallel_process(arr, psf, use_kwargs=True)\n",
    "#parallel_process(arr, centroid, use_kwargs=True)\n",
    "parallel_process(arr, get_radprof, use_kwargs=True, n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'PSZ1_G057.42-10.77'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = './data_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_radprof(name, outpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
