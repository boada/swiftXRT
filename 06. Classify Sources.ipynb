{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.table import Table, Column\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import ksone\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "\n",
    "# parallel processor\n",
    "from utilities import parallel_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_critical_value(alpha, n_trials):\n",
    "    ''' returns the critial value for a given alpha and number of trials'''\n",
    "    return ksone.ppf(1-alpha/2, n_trials)\n",
    "\n",
    "def ks_alpha(cv, n_trials):\n",
    "    ''' returns the alpha for a given critical value and number of trials'''\n",
    "    return ksone.sf(cv, n_trials) * 2\n",
    "\n",
    "def test_ks_cv(alphas=None, n_trials=None):\n",
    "\n",
    "    if not n_trials:\n",
    "        n_trials = range(5,15)\n",
    "    if not alphas:\n",
    "        alphas = [0.5, 0.1, 0.05, 0.02, 0.01]\n",
    "\n",
    "    if isinstance(n_trials, int) or isinstance(n_trials, float):\n",
    "        n_trials = range(n_trials - 2, n_trials + 2)\n",
    "        \n",
    "    # Print table headers\n",
    "    print('{:<6}|{:<6} Level of significance, alpha'.format(' ', ' '))\n",
    "    print('{:<6}|{:>8} {:>8} {:>8} {:>8} {:>8}'.format(*['Trials'] + alphas))\n",
    "    print('-' * 42)\n",
    "    # Print critical values for each n_trials x alpha combination\n",
    "    for t in n_trials:\n",
    "        print('{:6d}|{:>8.5f} {:>8.5f} {:>8.5f} {:>8.5f} {:>8.5f}'\n",
    "              .format(*[t] + [ks_critical_value(a, t) for a in alphas]))\n",
    "\n",
    "def ks_test_sources(name, outpath, plotting=False):\n",
    "    \n",
    "    # detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "\n",
    "    # mcmc fit data\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_mcmcfits.txt'):\n",
    "        return\n",
    "    else:\n",
    "        mcmcfits = f'{outpath}/{name}/{name}_mcmcfits.txt'\n",
    "        fit = Table.read(mcmcfits, format='ascii', header_start=0)\n",
    "                \n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "\n",
    "    # add a column for classifications!\n",
    "    try:   \n",
    "        # add the columns to the detection catalog\n",
    "        detects.add_column(Column(data=np.ones(len(detects)) * -1, name='Extended', dtype='>i8'))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    for indx, i in enumerate(detects['INDEX']):\n",
    "        if os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}.radprof'):\n",
    "            data = Table.read(f'{outpath}/{name}/{name}_vtp_{i}.radprof', format='ascii', header_start=2)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        # where is it in the mcmc file?\n",
    "        loc = fit['ID'] == i\n",
    "        if not loc.any(): # we didn't fit that one with mcmc\n",
    "            continue\n",
    "        bkg = fit['bg_50'][loc] # cnts/s/arcmin2\n",
    "\n",
    "        # convert to cnts/s\n",
    "        pixscale = 2.36 # arcs/pix\n",
    "        bkg *= pixscale**2 / 60**2 # cnts/s/arcmin2 * arcmin2/pix2\n",
    "        source_exp = data['x']/data['y'] - bkg * data['w'] # cnts/s - cnts/s/pix2 * pix2\n",
    "        psf_exp = data['psf'] / data['y'] # cnts/s\n",
    "        \n",
    "        # cummulative distributions\n",
    "        source_cum = np.cumsum(source_exp)\n",
    "        psf_cum = np.cumsum(psf_exp)\n",
    "        \n",
    "        # how far out do we want to go?\n",
    "        bins = 12\n",
    "        \n",
    "        # normalized\n",
    "        source_cum_n = source_cum / source_cum[bins - 1]\n",
    "        psf_cum_n = psf_cum / psf_cum[bins - 1]\n",
    "             \n",
    "        cv = ks_critical_value(0.05, bins)\n",
    "        \n",
    "        if plotting:\n",
    "            print((psf_cum_n - source_cum_n)[:bins])\n",
    "            print(i, (psf_cum_n[:bins] - source_cum_n[:bins]).max(), cv, \n",
    "                  (psf_cum_n[:bins] - source_cum_n[:bins]).max() > cv)\n",
    "        \n",
    "        if (psf_cum_n[:bins] - source_cum_n[:bins]).max() > cv:\n",
    "            detects['Extended'][indx] = 1\n",
    "#             print(i, 'NOT POINT SOURCE')\n",
    "        else:\n",
    "            detects['Extended'][indx] = 0\n",
    "#             print(i, 'POINT SOURCE')\n",
    "        \n",
    "        # plotting\n",
    "        if plotting:\n",
    "            # x-axis, in arcminutes\n",
    "            x = (data['r1'] + data['r2'])/ 2. / 60. * pixscale\n",
    "            plt.plot(x[:bins], source_cum_n[:bins], label=i)\n",
    "\n",
    "            ## if we want to try to use scipy's kstest\n",
    "            print('SciPy ks-test:')\n",
    "            result = ks_2samp(source_cum_n[:bins], psf_cum_n[:bins])\n",
    "            print(i, result)\n",
    "\n",
    "    detects.write(srcs, format='fits', overwrite=True)\n",
    "\n",
    "    # write out the regions\n",
    "    with open(f'{outpath}/{name}/{name}_vtp.reg', 'w') as reg:\n",
    "        reg.write(\"# Region file format: DS9 version 4.1\\n\")\n",
    "        reg.write('global color=cyan dashlist=8 3 width=1 font=\"helvetica 10 normal roman\" select=1 '\n",
    "                  'highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n')\n",
    "        reg.write('fk5\\n')\n",
    "        for j, xc, yc, rc, rotc, extd in detects[['INDEX', 'RA', 'DEC', 'R', 'ROTANG', 'Extended']]:\n",
    "            reg.write(f'ellipse({xc},{yc},{(rc[0] * 2.36):.3f}\",{(rc[1] * 2.36):.3f}\",{rotc:.3f}) ')\n",
    "            if extd > 0:\n",
    "                reg.write(f'# color=magenta ')\n",
    "            elif extd < 0:\n",
    "                reg.write('# color=cyan ')\n",
    "            else:\n",
    "                 reg.write(f'# color=yellow ')\n",
    "            reg.write(f'text={{{j}}}\\n')\n",
    "    \n",
    "    \n",
    "    if plotting:\n",
    "        plt.plot(x[:bins], psf_cum_n[:bins], ls='--', label='PSF')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "\n",
    "###\n",
    "# This is the order you should call the functions. \n",
    "# There are other functions in this notebook, but these are the only ones \n",
    "# that should be called directly.\n",
    "###\n",
    "\n",
    "parallel_process(arr, ks_test_sources, use_kwargs=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For testing ###\n",
    "\n",
    "outpath = './data'\n",
    "# name = 'PSZ2_G094.00+27.41'\n",
    "name = 'PSZ2_G003.21-76.04'\n",
    "ks_test_sources(name, outpath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Legacy code I didn't want to throw away\n",
    "##############\n",
    "\n",
    "# def integ_beta_model(r, rc, beta):\n",
    "#     # from notebook 4a\n",
    "    \n",
    "#     ''' 2pi*r integral of the above Beta model with 3 parameters. \n",
    "#     r -- r\n",
    "#     rc -- core radius\n",
    "#     beta -- powerlaw slope\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     rc2 = rc * rc\n",
    "    \n",
    "#     return np.pi * rc2 / (1 - beta) * ((1 + r**2 / rc2)**(1 - beta) - 1)\n",
    "\n",
    "\n",
    "#         targetr1 = integ_beta_model(data['r1'], rc=(fit['rc_50'][loc] * 60/2.36), beta=fit['beta_50'][loc])\n",
    "#         targetr2 = integ_beta_model(data['r2'], rc=(fit['rc_50'][loc] * 60/2.36), beta=fit['beta_50'][loc])\n",
    "\n",
    "#         target = targetr2 - targetr1\n",
    "#         source_exp = target / data['y'] # y is the exposure time in each bin\n",
    "    \n",
    "#         # same for the psf -- I've already computed the profiles and stored them in the file\n",
    "#         # see notebook 4a\n",
    "#         psf_exp = data['psf'] / data['y']\n",
    "\n",
    "#         # cummulative distributions\n",
    "#         source_cum = np.cumsum(source_exp)\n",
    "#         psf_cum = np.cumsum(psf_exp)\n",
    "        \n",
    "#         # how far out do we want to go?\n",
    "#         bins = 30\n",
    "        \n",
    "#         # normalized\n",
    "#         source_cum_n = source_cum / source_cum[bins - 1]\n",
    "#         psf_cum_n = psf_cum / psf_cum[bins - 1]\n",
    "\n",
    "# #         # make CDFs\n",
    "#         source_cum_n = source_cum / source_cum[bins - 1]\n",
    "#         psf_cum_n = psf_cum / psf_cum[bins - 1]\n",
    "        \n",
    "#         pixscale = 2.36 # arcs/pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
