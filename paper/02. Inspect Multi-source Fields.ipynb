{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from astropy.table import Table, Column\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Table.read('./catalogs/results_table_full_0.5_2.0.fits')\n",
    "results_df = results.to_pandas()\n",
    "results_df = results_df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_mask = results_df[['NAME', 'RA_detc']].duplicated('NAME', keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_cat = results_df[dup_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_cat_tab = Table.from_pandas(dup_cat)\n",
    "dup_cat_tab.filled(-1.0).write('./catalogs/results_table_dups_0.5_2.0.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column for Duplicates\n",
    "\n",
    "Add a column to the results table indicating whether or not the source is a duplicate\n",
    "\n",
    "Then we are gonna mark all the current duplicates as true and then loop through them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.add_column(Column(data=False, name='DUPLICATE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['DUPLICATE'][dup_cat.index.values] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to read previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./catalogs/results_table_inspected_0.5_2.0.fits'):\n",
    "    results_previous = Table.read('./catalogs/results_table_inspected_0.5_2.0.fits')\n",
    "    results_previous_df = results_previous.to_pandas()\n",
    "    results_previous_df = results_previous_df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "    columns = ['NAME', 'INDEX', 'DUPLICATE']\n",
    "    results_p_df_small = results_previous_df[columns]\n",
    "    \n",
    "    # merge the previous results into the new results\n",
    "    x = results_df.merge(results_p_df_small, how='outer', left_on=['NAME', 'INDEX'], right_on=['NAME', 'INDEX'])\n",
    "    \n",
    "    # there are no new fields/indexes\n",
    "    if not x.DUPLICATE.isna().any():\n",
    "        results_df = x # write the merged df back \n",
    "        results = Table.from_pandas(results_df)\n",
    "        results.filled(-1.0).write('./catalogs/results_table_inspected_0.5_2.0.fits', overwrite=True)\n",
    "    \n",
    "    else:\n",
    "        # here we are gonna check if there are duplicates\n",
    "        if x[x.DUPLICATE.isna()][['NAME', 'INDEX']].duplicated('NAME', keep=False).any():\n",
    "            print('THERE ARE DUPLICATES!!! Need to inspect.')\n",
    "            \n",
    "            \n",
    "        else: # there are no duplicates\n",
    "            x.loc[x.DUPLICATE.isna(), 'DUPLICATE'] = False\n",
    "            results_df = x # write the merged df back\n",
    "            results_df.DUPLICATE = results_df.DUPLICATE.astype(bool) # fix a problem when writing the data out\n",
    "            results = Table.from_pandas(results_df)\n",
    "            results.filled(-1.0).write('./catalogs/results_table_inspected_0.5_2.0.fits', overwrite=True)\n",
    "            \n",
    "            print('THERE ARE NO DUPLICATES!!! Catalog updated.')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are gonna visually inspect the duplicate fields\n",
    "\n",
    "This is gonna let us identify which is the \"primary\" source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the pandas iterrows because the astropy one sucks\n",
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a catalog mask\n",
    "\n",
    "fig = plt.figure(1, figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "name_old= ''\n",
    "for index, row in results_df.iterrows():\n",
    "    if not row.DUPLICATE:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        name = row.NAME.decode().replace(' ', '_')\n",
    "\n",
    "        if name == name_old:\n",
    "            pass\n",
    "        else:\n",
    "            display.clear_output(wait=True)\n",
    "            jpgfile = f'../data/{name}/{name}_XRT_vtp_zoom.png'\n",
    "            jpg_array = io.imread(jpgfile)\n",
    "            name_old = name\n",
    "            \n",
    "            ax.imshow(jpg_array, origin='upper', interpolation='bicubic')\n",
    "            ax.set_title(f'{name}')\n",
    "\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['bottom'].set_visible(False)\n",
    "            ax.yaxis.set_ticks([])\n",
    "            ax.xaxis.set_ticks([])\n",
    "\n",
    "            plt.show()\n",
    "            display.display(fig)\n",
    "            \n",
    "    except NameError:\n",
    "        display.clear_output(wait=True)\n",
    "        jpgfile = f'../data/{name}/{name}_XRT_vtp_zoom.png'\n",
    "        jpg_array = io.imread(jpgfile)\n",
    "        name_old = name\n",
    "        \n",
    "        ax.imshow(jpg_array, origin='upper', interpolation='bicubic')\n",
    "        ax.set_title(f'{name}')\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.yaxis.set_ticks([])\n",
    "        ax.xaxis.set_ticks([])\n",
    "\n",
    "        plt.show()\n",
    "        display.display(fig)\n",
    "\n",
    "    x = input(f\"Is {row.INDEX} the main source? [n]y.\")\n",
    "    \n",
    "    if x == 'y':\n",
    "        print('updated')\n",
    "        results_df.loc[index, 'DUPLICATE'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results!\n",
    "\n",
    "So we don't have to look at all of them again. \n",
    "\n",
    "Uncomment the next cell if you are gonna redo the inspections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Table.from_pandas(results_df)\n",
    "results.filled(-1.0).write('./catalogs/results_table_inspected_0.5_2.0.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
