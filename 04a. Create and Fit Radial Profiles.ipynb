{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy import table\n",
    "from astropy.table import Table, Column\n",
    "import tempfile\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "import emcee\n",
    "import corner\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "import astropy.units as u\n",
    "       \n",
    "from regions import PixCoord, EllipsePixelRegion, CircleAnnulusPixelRegion\n",
    "\n",
    "from math import sqrt, sin, cos, pow   \n",
    "                \n",
    "# parallel processor\n",
    "from utilities import parallel_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def compound_regions(region_list, img_size=1000):\n",
    "    for r in region_list:\n",
    "        # handle the first pass when we only have one part\n",
    "        try:\n",
    "            m = r.to_mask()\n",
    "            compound_region = compound_region + m.to_image((img_size, img_size))\n",
    "        except NameError:\n",
    "            m = r.to_mask()\n",
    "            compound_region = m.to_image((img_size, img_size))\n",
    "\n",
    "    return compound_region\n",
    "\n",
    "\n",
    "def check_exe(exe, verb=\"yes\"):\n",
    "    ''' Checks to make sure we have the appropriate system command available.\n",
    "    If we don't it raises an exception.\n",
    "\n",
    "    '''\n",
    "\n",
    "    path = os.environ['PATH'].split(':')\n",
    "    for p in path:\n",
    "        f = os.path.join(p, exe)\n",
    "        if os.path.isfile(f):\n",
    "            if verb:\n",
    "                print(\"# Found %s in %s\" % (exe, f), file=sys.stderr)\n",
    "            return True\n",
    "    # it wasn't found\n",
    "    print(\"# ERROR: Couldn't find %s\" % exe, file=sys.stderr)\n",
    "    raise FileNotFoundError(exe)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_model(So, r, rc, beta):\n",
    "    ''' Beta model with 3 parameters. \n",
    "    So -- normalization\n",
    "    rc -- core radius\n",
    "    beta -- powerlaw slope\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return So * ( 1.0 + (r / rc)**2)**(-3.0 * beta + 0.5)\n",
    "\n",
    "def chi2(model, y, y_err):\n",
    "    '''Chi error. We are going to square this to make it the chi2 error.'''\n",
    "    return np.sum(((model - y) / y_err)**2)\n",
    "\n",
    "def like(theta, x, y, yerr):\n",
    "    So, rc, beta, bg = theta\n",
    "    model = beta_model(So, x, rc, beta) + bg\n",
    "    #return -0.5 * np.sum(np.log(2 * np.pi * yerr) + (y - model)**2 / yerr)\n",
    "    return -chi2(model, y, yerr)\n",
    "\n",
    "def prior(theta):\n",
    "    So, rc, beta, bg = theta\n",
    "    if So < 0:\n",
    "        return -np.inf\n",
    "    elif rc < 0 or rc > 10:\n",
    "        return -np.inf\n",
    "    elif beta < 0 or beta > 3: \n",
    "        return -np.inf\n",
    "    elif bg < 0 or bg > 1:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def prob(theta, x, y, yerr):\n",
    "    lp = prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + like(theta, x, y, yerr)\n",
    "\n",
    "def fit_radprof(name, outpath):\n",
    "    \n",
    "    # swift pixelscale in degrees\n",
    "    pixsc =  6.548089E-04 * 3600\n",
    "    \n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "        # now we need to read the individual detections\n",
    "        detects = Table.read(srcs, hdu=1)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    # we are going to fit profiles to the top 3 biggest \n",
    "    detects.sort(['NET_COUNTS'], reverse=True)\n",
    "    \n",
    "    # open a file to write out the results\n",
    "    outfile = open(f'{outpath}/{name}/{name}_mcmcfits.txt', 'w')    \n",
    "    outfile.write('# Field ID So_50 So_84 So_16 rc_50 rc_84 rc_16 beta_50 beta_84 beta_16 bg_50 bg_84 bg_16\\n')\n",
    "    \n",
    "    # loop over the sources -- only the first 3\n",
    "    for i in detects['INDEX'][:3]:\n",
    "        \n",
    "        if os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}.radprof'):\n",
    "            data = Table.read(f'{outpath}/{name}/{name}_vtp_{i}.radprof', format='ascii', header_start=2)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        # don't try to fit things if there isn't any data\n",
    "        if len(data) <= 60:\n",
    "            continue\n",
    "        \n",
    "        # x-axis, in arcminutes\n",
    "        x = (data['r1'] + data['r2'])/ 2. / 60. * pixsc\n",
    "        \n",
    "        # this is the parameter fitting\n",
    "        ndim = 4  # number of parameters in the model\n",
    "        nwalkers = 100  # number of MCMC walkers\n",
    "        nburn = 100  # \"burn-in\" period to let chains stabilize\n",
    "        nsteps = 500  # number of MCMC steps to take\n",
    "\n",
    "        pos = [np.array([0.001, 1., 1., 0.001]) + 1e-4 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, prob, args=(x, data['sb'], data['sb_err']))\n",
    "        sampler.run_mcmc(pos, nsteps)\n",
    "        emcee_trace = sampler.get_chain(discard=nburn, thin=15, flat=True)\n",
    "        \n",
    "        # plot the result\n",
    "        fignum = np.random.randint(1, 1000)\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6.5, 5), num=fignum)\n",
    "        # data\n",
    "        ax.errorbar(x, data['sb'], yerr=data['sb_err'], fmt='o', label='data')\n",
    "        for So, rc, beta, bg in emcee_trace[np.random.randint(len(emcee_trace), size=100)]:\n",
    "            ax.plot(x, beta_model(So, x, rc, beta) + bg, color='k', alpha=0.1)\n",
    "        ylims = ax.get_ylim()\n",
    "        \n",
    "        #fit -- median (and error) values\n",
    "        So, rc, beta, bg = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(emcee_trace, [16, 50, 84], axis=0)))\n",
    "        ax.plot(x, beta_model(So[0], x, rc[0], beta[0]) + bg[0], label=r'$\\beta$ + bg')\n",
    "        ax.plot(x, beta_model(So[0], x, rc[0], beta[0]), label=r'$\\beta$')\n",
    "        \n",
    "        # write out the fit parameters\n",
    "        outfile.write(f'{name} ')\n",
    "        outfile.write(f'{i} ')\n",
    "        outfile.write(f'{So[0]:.5f} {So[1]:.5f} {So[2]:.5f} ')\n",
    "        outfile.write(f'{rc[0]:.5f} {rc[1]:.5f} {rc[2]:.5f} ')\n",
    "        outfile.write(f'{beta[0]:.5f} {beta[1]:.5f} {beta[2]:.5f} ')\n",
    "        outfile.write(f'{bg[0]:.5f} {bg[1]:.5f} {bg[2]:.5f}\\n')\n",
    "\n",
    "        # rc and bg lines\n",
    "        ax.axhline(bg[0], label='bg', zorder=0, lw=1)\n",
    "        ax.axvline(rc[0], zorder=0, lw=1)\n",
    "        \n",
    "        ax.semilogy()\n",
    "\n",
    "        if ylims[0] < 1e-5:\n",
    "            ax.text(rc[0] + 0.1, 2e-5, f\"rc = {rc[0]:.2f}'\", rotation='vertical', ha='left')\n",
    "            ax.set_ylim(1e-5, ylims[1])\n",
    "        else:\n",
    "            ax.text(rc[0] + 0.1, ylims[0], f\"rc = {rc[0]:.2f}'\", rotation='vertical', ha='left')\n",
    "            ax.set_ylim(ylims)\n",
    "        ax.set_xlabel('Radius [arcmin]')\n",
    "        ax.set_ylabel('Flux [cnts/s]')\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        fig.savefig(f'{outpath}/{name}/{name}_radproffit_{i}.png', bbox='tight', dpi=180)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # add a corner plot of the fits.\n",
    "        # plot the bg and So in log to make them fit on the plot better\n",
    "        emcee_trace[:,0] = np.log(emcee_trace[:,0])\n",
    "        emcee_trace[:,3] = np.log(emcee_trace[:,3])\n",
    "        f = corner.corner(emcee_trace, labels=['log So', 'rc', r'$\\beta$', 'log bg'],\n",
    "                    bins=[50, 50, 50, 50],\n",
    "                    smooth=True,\n",
    "                    fill_contours=True)\n",
    "\n",
    "        f.savefig(f'{outpath}/{name}/{name}_corner_{i}.png', bbox='tight')\n",
    "        plt.close(f)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radprof(name, outpath):\n",
    "    pixscale = 6.548089E-04 * 3600\n",
    "\n",
    "    # model parameters\n",
    "    params = {}\n",
    "    params['n'] = 75\n",
    "    params['r0'] = 0 \n",
    "    params['dr'] = 4\n",
    "\n",
    "    # check for files\n",
    "    # events image\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200.fits'):\n",
    "        return\n",
    "    else:\n",
    "        evnts = f'{outpath}/{name}/{name}_img_50-200.fits'\n",
    "    # expo map\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_exp.fits'):\n",
    "        return\n",
    "    else:\n",
    "        expmap = f'{outpath}/{name}/{name}_exp.fits'   \n",
    "    # detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "\n",
    "    # load the data\n",
    "    evnt_data = fits.getdata(evnts)\n",
    "    expmap_data = fits.getdata(expmap)\n",
    "\n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "    \n",
    "    # we are going to compute profiles for the 10 biggest -- this is for speed. \n",
    "    detects.sort(['NET_COUNTS'], reverse=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        # mask out all sources except the source we are working with\n",
    "        src_mask = [j for j in range(len(detects)) if j != i]\n",
    "\n",
    "        regs = []\n",
    "        \n",
    "        ### have to subtract 1 from the region positions, because FITS are 1-index'd and python\n",
    "        ### is 0-index'd.\n",
    "        \n",
    "        \n",
    "        for idx, xc1, yc1, rc, rotc in detects[src_mask][['INDEX', 'X', 'Y', 'R', 'ROTANG']]:\n",
    "            ellipse_region = EllipsePixelRegion(center=PixCoord(x=xc1 -1, y=yc1 -1),\n",
    "                                         width=2 * rc[0], height=2 * rc[1], angle=rotc * u.deg, \n",
    "                                            meta={'ID':idx})\n",
    "            regs.append(ellipse_region)\n",
    "\n",
    "        # create the compound regions\n",
    "        cmp_reg = compound_regions(regs, evnt_data.shape[0])\n",
    "        # invert the comp region -- we want the places where there aren't regions\n",
    "        cmp_regmask = np.where(cmp_reg == 0, 1, 0)\n",
    "\n",
    "        with open(f'{outpath}/{name}/{name}_vtp_{detects[\"INDEX\"][i]}.radprof', 'w') as radprof:\n",
    "            radprof.write(f\"# source number and position: {name}_{detects['INDEX'][i]} \"\n",
    "                          f\"{detects['X'][i]:.3f} {detects['Y'][i]:.3f}\\n\")\n",
    "            radprof.write(f\"# profile parameters: {params['n']} {params['r0']} {params['dr']}\\n\")\n",
    "            radprof.write(f\"# bin r1 r2 x y w sb sb_err\\n\")\n",
    "        \n",
    "            for irad in range(params['n']):\n",
    "                r1 = params['r0'] + irad * params['dr']\n",
    "                r2 = params['r0'] + (irad + 1) * params['dr']\n",
    "\n",
    "                center = PixCoord(x=detects['X'][i]-1, y=detects['Y'][i]-1)\n",
    "                ann_reg = CircleAnnulusPixelRegion(center=center, inner_radius=r1, outer_radius=r2)\n",
    "                # make it into an image\n",
    "                ann_regmask = compound_regions([ann_reg], evnt_data.shape[0])\n",
    "\n",
    "                # combine the regions with the annulus.\n",
    "                final_regmask = (ann_regmask * cmp_regmask)\n",
    "                final_regmask_inv = np.where(final_regmask == 0, 1, 0) # this is the final mask for the data\n",
    "\n",
    "                evnt_data_masked = ma.masked_array(evnt_data, mask=final_regmask_inv)\n",
    "                expmap_data_masked = ma.masked_array(expmap_data, mask=final_regmask_inv)\n",
    "\n",
    "                x = evnt_data_masked.sum()\n",
    "                y = expmap_data_masked.mean()\n",
    "                w = expmap_data_masked.count()\n",
    "\n",
    "                sb = x / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                err_gehrels = sqrt(x + 0.75)\n",
    "                sbe = (1. + err_gehrels) / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "\n",
    "                radprof.write(f'{irad:3d} {r1:7d} {r2:7d} {x:9.1f} {y:9.1f} {w:9.1f} {sb:12.4e} {sbe:12.4e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radprof_dmstat(name, outpath, overwrite=False):\n",
    "                   \n",
    "    # Swift XRT pixel scale\n",
    "    # 1 pixel = 6.548089E-04 * 3600 arcsec\n",
    "    pixscale = 6.548089E-04 * 3600\n",
    "    \n",
    "    # model parameters\n",
    "    params = {}\n",
    "    params['n'] = 75\n",
    "    params['r0'] = 0 \n",
    "    params['dr'] = 4\n",
    "    \n",
    "    # check for files\n",
    "    # events image\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200.fits'):\n",
    "        return\n",
    "    else:\n",
    "        evnts = f'{outpath}/{name}/{name}_img_50-200.fits'\n",
    "    # expo map\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_exp.fits'):\n",
    "        return\n",
    "    else:\n",
    "        expmap = f'{outpath}/{name}/{name}_exp.fits'   \n",
    "    # detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "    \n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "    \n",
    "    # we are going to compute profiles for the 10 biggest -- this is for speed. \n",
    "    detects.sort(['NET_COUNTS'], reverse=True)\n",
    "    \n",
    "    # loop over the sources -- component is the source ID number\n",
    "    for i, xc, yc in detects[['INDEX', 'X', 'Y']][:10]:\n",
    "        # decide whether we need to redo the profile\n",
    "        if overwrite:\n",
    "            pass\n",
    "        elif os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}_dmstat.radprof'):\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            data = Table.read(f'{outpath}/{name}/{name}_vtp_{i}_dmstat.radprof', format='ascii', header_start=2)\n",
    "            if len(data) >= 70:\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "        # output file\n",
    "        with open(f'{outpath}/{name}/{name}_vtp_{i}_dmstat.radprof', 'w') as radprof:\n",
    "            radprof.write(f\"# source number and position: {name}_{i} {xc:.3f} {yc:.3f}\\n\")\n",
    "            radprof.write(f\"# profile parameters: {params['n']} {params['r0']} {params['dr']}\\n\")\n",
    "            radprof.write(f\"# bin r1 r2 x y w sb sb_err\\n\")\n",
    "\n",
    "            fd2, path2 = tempfile.mkstemp() # this is the temp file to store the awk output\n",
    "            for irad in range(params['n']):\n",
    "                r1 = params['r0'] + irad * params['dr']\n",
    "                r2 = params['r0'] + (irad + 1) * params['dr']\n",
    "\n",
    "                fd, path = tempfile.mkstemp()\n",
    "                with os.fdopen(fd, 'w') as reg:\n",
    "                    reg.write(\"# Region file format: CIAO version 1.0\\n\")\n",
    "                    reg.write(f\"+annulus({xc},{yc},{r1},{r2})\\n\")\n",
    "                    for j, xc1, yc1, rc, rotc in detects[['INDEX', 'X', 'Y', 'R', 'ROTANG']]:\n",
    "                        if not j == i:\n",
    "                            reg.write(f\"-ellipse({xc1},{yc1},{rc[0]},{rc[1]},{rotc})\\n\")\n",
    "                          \n",
    "                #  No. of counts from data image\n",
    "                cmd = f\"dmstat '{evnts}[(x,y)=region({path})]' centroid- | grep sum | awk '{{print $2}}' > {path2}\"\n",
    "                #print(cmd)\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    x = tmp.readlines()[0][:-1]\n",
    "                x = float(x)\n",
    "\n",
    "                #  Mean exposure\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep mean | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    y = tmp.readlines()[0][:-1]\n",
    "                y = float(y)\n",
    "\n",
    "                #  No. of pixels\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep good | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    w = tmp.readlines()[0][:-1]\n",
    "                w = float(w)\n",
    "\n",
    "                os.remove(path)\n",
    "            \n",
    "                try:\n",
    "                    sb = x / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                    err_gehrels = sqrt(x + 0.75)\n",
    "                    sbe = (1. + err_gehrels) / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                    radprof.write(f\"{irad:3d} {r1:7d} {r2:7d} {x:9.1f} {y:9.1f} {w:9.1f} {sb:12.4e} {sbe:12.4e}\\n\")\n",
    "                except ZeroDivisionError:\n",
    "                    print(f'{name}_{i} -- Zero Division in sb calculation! -- bin number {irad:3d}')\n",
    "                    print(f'more info {w:.3f} {y:.3f}')\n",
    "\n",
    "            os.remove(path2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'erg/s/cm2' contains multiple slashes, which is discouraged by the FITS standard [astropy.units.format.generic]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ae5272f834fa88c6641dadb3ff508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1943), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "\n",
    "###\n",
    "# This is the order you should call the functions. \n",
    "# There are other functions in this notebook, but these are the only ones \n",
    "# that should be called directly.\n",
    "###\n",
    "\n",
    "# parallel_process(arr, get_radprof, use_kwargs=True, n_jobs=6)\n",
    "parallel_process(arr, fit_radprof, use_kwargs=True, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For testing ###\n",
    "\n",
    "outpath = './data_full'\n",
    "name = 'PSZ2_G274.73-32.20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_radprof(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_radprof(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
