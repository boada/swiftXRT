{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog(ra, dec, target, outpath, table='swiftmastr', oformat='fits'):\n",
    "\n",
    "    # build the command\n",
    "    cmd = (f'./browse_extract_wget.pl table={table} position={ra},{dec} '\n",
    "           f'outfile={outpath}/{target}/{target}xrt.fits format={oformat} radius=10')\n",
    "\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(target, outpath):\n",
    "\n",
    "    # at least one file was 0 bytes... \n",
    "    try:\n",
    "        cat = fits.getdata(f'{outpath}/{target}/{target}xrt.fits')\n",
    "    except OSError:\n",
    "        return\n",
    "\n",
    "    if cat.shape[0] < 1:\n",
    "        return\n",
    "\n",
    "    for i in range(cat.shape[0]):\n",
    "        obsid = cat['obsid'][i]\n",
    "        t = Time(cat['start_time'][i], format='mjd')\n",
    "        y, m = t.iso.split('-')[:2]\n",
    "\n",
    "        wget_base = (f'wget -P {outpath}/{target} -q -nH --no-check-certificate --cut-dirs=5 '\n",
    "                '-r -l0 -c -nc -np -R \"index*\" -erobots=off --retr-symlinks '\n",
    "                f'https://heasarc.gsfc.nasa.gov/FTP/swift/data/obs/{y}_{m}/')\n",
    "             \n",
    "        for prod in ['xrt', 'auxil', 'log']:\n",
    "            wget = f'{wget_base}{obsid}/{prod}/'\n",
    "            os.system(wget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PSZcatalog(unconf=False):\n",
    "    from astropy.table import Table                                                       \n",
    "    from numpy import append as npappend                                             \n",
    "\n",
    "    datapath = f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs'\n",
    "    \n",
    "    ps1 = Table.read(f'{datapath}/PSZ1v2.1.fits')\n",
    "    ps2 = Table.read(f'{datapath}/PSZ2v1.fits')\n",
    "\n",
    "    # convert to pandas\n",
    "    df1 = ps1.to_pandas()\n",
    "    df2 = ps2.to_pandas()\n",
    "\n",
    "    if unconf:\n",
    "        # only get unconfirmed sources                                                   \n",
    "        df1 = df1.loc[df1['VALIDATION'] <= 3]                                         \n",
    "        df2 = df2.loc[df2['VALIDATION'] == -1]  \n",
    "    \n",
    "    # clean up strings -- not required\n",
    "    df1 = df1.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "    df2 = df2.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "\n",
    "    # merge the catalogs together\n",
    "    df_m = df1.merge(df2, how='outer', left_on='INDEX', right_on='PSZ', suffixes=('_PSZ1', '_PSZ2'))\n",
    "    \n",
    "    # get the columns that we want\n",
    "    cols = df_m.columns[[0, 1, 4, 5, 8, 29, 33, 34, 37, 38, 40, 51]]\n",
    "    df_final = df_m[cols]\n",
    "\n",
    "    # remerge to find bits that were missing                                        \n",
    "    df_final_bigger = df_final.merge(df2, how='left', left_on='INDEX_PSZ1',         \n",
    "                                 right_on='PSZ')\n",
    "    # fill in nans                                                                  \n",
    "    for col in ['NAME', 'RA', 'DEC', 'SNR', 'REDSHIFT', 'INDEX']:                   \n",
    "        df_final_bigger[col+'_PSZ2'] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col])\n",
    "    # fill in nans                                                                  \n",
    "    for col in ['NAME', 'RA', 'DEC', 'SNR', 'REDSHIFT', 'INDEX']:\n",
    "        df_final_bigger[col+'_PSZ2'] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col])\n",
    "    for col in ['NAME', 'RA', 'DEC']:\n",
    "        df_final_bigger[col] = df_final_bigger[col+'_PSZ2'].fillna(df_final_bigger[col+'_PSZ1'])\n",
    "\n",
    "    df_final_bigger = df_final_bigger[npappend(df_final_bigger.columns[:12].values, ['NAME', 'RA', 'DEC'])]\n",
    "\n",
    "    return df_final_bigger\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_info(outpath, idx, data):\n",
    "    target = data.iloc[idx]['NAME'].replace(' ', '_')\n",
    "    cols = data.columns.tolist()\n",
    "    vals = data.iloc[idx]\n",
    "    # convert the values into all strings\n",
    "    vals_str = [f'{i:.8}' if isinstance(i, float) else i for i in vals.values.tolist()]\n",
    "    with open(f'{outpath}/{target}/{target}.info', 'w') as f:\n",
    "        f.write(f'{\",\".join(cols)}\\n')\n",
    "        f.write(f'{\",\".join(vals_str)}\\n')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "for i, (ra, dec, name) in enumerate(zip(data['RA'], data['DEC'], data['NAME'])):\n",
    "\n",
    "    #print(name)\n",
    "    name = name.replace(' ', '_')\n",
    "\n",
    "    if not os.path.isdir(f'{outpath}/{name}'):\n",
    "        os.makedirs(f'{outpath}/{name}')\n",
    "\n",
    "    #get_catalog(ra, dec, f'{name}', outpath)\n",
    "    #write_info(outpath, i, data)\n",
    "    get_files(f'{name}', outpath)\n",
    "    \n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
