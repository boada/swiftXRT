{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "import astropy.units as u\n",
    "from glob import glob\n",
    "import shlex\n",
    "                \n",
    "# parallel processor\n",
    "from utilities import parallel_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows us to run the pipeline not interactively. \n",
    "os.environ['HEADASNOQUERY'] = ''\n",
    "os.environ['HEADASPROMPT'] = '/dev/null'\n",
    "# os.environ['PFILES'] = '/tmp/$$.tmp/pfiles;$HEADAS/syspfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runnh(ra, dec):\n",
    "    '''This function will automatically run the ftool nh\n",
    "    on a given RA and Dec in J2000 equinox coordinates'''\n",
    "\n",
    "    nh = 0\n",
    "    cmd = f'nh equinox=2000 ra={ra} dec={dec}'\n",
    "    args = shlex.split(cmd)\n",
    "    out = \"\"\n",
    "\n",
    "    with subprocess.Popen(args,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          universal_newlines=True) as proc:\n",
    "\n",
    "        proc.wait()\n",
    "        out = proc.stdout.read()\n",
    "\n",
    "    outlines = out.split(\"\\n\")\n",
    "    for line in outlines:\n",
    "        if \"Weighted average\" in line:\n",
    "            nh = line.split(\" \")[-1]\n",
    "\n",
    "    return out, float(nh)\n",
    "\n",
    "def GetLuminosity(flux, distance):\n",
    "        #assumes distance is in mpc\n",
    "        #converts to cm\n",
    "        #returns L = (4piD^2)*f\n",
    "        distance = 3.86E24 * distance\n",
    "        return 4*math.pi*distance*distance*flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immediate_subdirectories(a_dir):\n",
    "    ''' Get a list of a directorys immediate subdirectories'''\n",
    "    return [os.path.join(a_dir, name) for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "def get_immediate_subfiles(a_dir):\n",
    "    ''' Get a list of all the FILES in a directory'''\n",
    "    return [os.path.join(a_dir, name) for name in os.listdir(a_dir)\n",
    "            if os.path.isfile(os.path.join(a_dir, name))]\n",
    "\n",
    "def check_exe(exe, verb=False):\n",
    "    ''' Checks to make sure we have the appropriate system command available.\n",
    "    If we don't it raises an exception.\n",
    "\n",
    "    '''\n",
    "\n",
    "    path = os.environ['PATH'].split(':')\n",
    "    for p in path:\n",
    "        f = os.path.join(p, exe)\n",
    "        if os.path.isfile(f):\n",
    "            if verb:\n",
    "                print(\"# Found %s in %s\" % (exe, f), file=sys.stderr)\n",
    "            return True\n",
    "    if verb:\n",
    "        # it wasn't found\n",
    "        print(\"# ERROR: Couldn't find %s\" % exe, file=sys.stderr)\n",
    "    raise FileNotFoundError(exe)\n",
    "    return False\n",
    "\n",
    "def set_env():\n",
    "    os.environ['PFILES'] = f\"/tmp/{os.getpid()}.tmp/pfiles;$HEADAS/syspfiles\"\n",
    "    pfiles = f'/tmp/{os.getpid()}.tmp/pfiles'\n",
    "    if not os.path.isdir(pfiles):\n",
    "        os.makedirs(pfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_beta_model(So, rc, beta, bkg):\n",
    "    ''' Solves for where (radius) the beta model is equal to the background\n",
    "    \n",
    "    Make sure you keep track of the units going into all this. You wanna make sure the radius comes\n",
    "    out as something that makes sense.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    a = -3 * beta + 0.5 \n",
    "    \n",
    "    b = (bkg/So)**(1/a) - 1\n",
    "    \n",
    "    c = b * rc**2\n",
    "    \n",
    "    return np.sqrt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bkg_regions(name, outpath):\n",
    "    ''' For each obs id we are going to create a background region. 10.5 arcmin\n",
    "    centered on the pointing position of each observation. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt', recursive=True)\n",
    "    \n",
    "    if len(files) < 1:\n",
    "        return name\n",
    "    \n",
    "    # create a place for the products\n",
    "    if not os.path.isdir(f'{outpath}/{name}/spec_files'):\n",
    "        os.makedirs(f'{outpath}/{name}/spec_files')\n",
    "    \n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "        \n",
    "        # get pointing\n",
    "        point_ra = fits.getheader(f_in, ext=0)['RA_PNT']\n",
    "        point_dec = fits.getheader(f_in, ext=0)['DEC_PNT']\n",
    "        \n",
    "        # we cannot use the X/Y position in the catalog because it was detected in \n",
    "        # the combined frame. We need to use the RA/DEC and then find the pixel positions\n",
    "        # in the individual frames. Lame.\n",
    "        # WCS info to convert world coords to pixels \n",
    "        hdr = fits.getheader(f_in.replace('cl.evt', 'ex.img'))\n",
    "        w = wcs.WCS(hdr)\n",
    "        pixels = w.wcs_world2pix(point_ra, point_dec, 0)\n",
    "        \n",
    "        obs_id = f_in.split('/')[-2]\n",
    "        \n",
    "        # write out the regions\n",
    "        with open(f'{outpath}/{name}/spec_files/{obs_id}_bkg.reg', 'w') as reg:     \n",
    "            # write the background region\n",
    "            reg.write(f\"circle({pixels[0]:.5f},{pixels[1]:.5f},{(11 * 60 /2.36):.5f})\\n\")\n",
    "\n",
    "            for j, xc, yc, rc, rotc in detects[['INDEX', 'RA', 'DEC', 'R', 'ROTANG']]:\n",
    "                pixels = w.wcs_world2pix(xc, yc, 0)\n",
    "                reg.write(f'-ellipse({pixels[0]:.5f},{pixels[1]:.5f},{rc[0]:.3f},{rc[1]:.3f},{rotc:.3f})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_src_regions(name, outpath):\n",
    "    ''' For each obs id we are going to create a background region. 10.5 arcmin\n",
    "    centered on the pointing position of each observation. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt', recursive=True)\n",
    "    \n",
    "    if len(files) < 1:\n",
    "        return name\n",
    "    \n",
    "    # create a place for the products\n",
    "    if not os.path.isdir(f'{outpath}/{name}/spec_files'):\n",
    "        os.makedirs(f'{outpath}/{name}/spec_files')\n",
    "    \n",
    "    # get the MCMC fits:\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_mcmcfits.txt'):\n",
    "        mcmcfit = Table.read(f'{outpath}/{name}/{name}_mcmcfits.txt', format='ascii', header_start=0)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_mcmcfits.txt')\n",
    "\n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "        \n",
    "        obs_id = f_in.split('/')[-2]\n",
    "        \n",
    "        # we cannot use the X/Y position in the catalog because it was detected in \n",
    "        # the combined frame. We need to use the RA/DEC and then find the pixel positions\n",
    "        # in the individual frames. Lame.\n",
    "        # WCS info to convert world coords to pixels \n",
    "        hdr = fits.getheader(f_in.replace('cl.evt', 'ex.img'))\n",
    "        w = wcs.WCS(hdr)        \n",
    "        \n",
    "        # now we have to loop through the detections\n",
    "        for j, xc, yc in detects[['INDEX', 'RA', 'DEC']]:\n",
    "            \n",
    "            # we didn't fit all the sources with the MCMC\n",
    "            if j not in mcmcfit['ID']:\n",
    "                continue\n",
    "                \n",
    "            # write out the regions\n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg', 'w') as reg:\n",
    "                # Here we are going to draw a circle with a radius where the beta model just fades into\n",
    "                # the background. These values come from the MCMC fits done previously.\n",
    "                radius = inv_beta_model(mcmcfit['So_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['rc_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['beta_50'][mcmcfit['ID'] == j],\n",
    "                                        mcmcfit['bg_50'][mcmcfit['ID'] == j]\n",
    "                                       )\n",
    "            \n",
    "                pixels = w.wcs_world2pix(xc, yc, 0)\n",
    "            \n",
    "                reg.write(f\"circle({pixels[0]},{pixels[1]},{(radius[0] * 60 / 2.36):.3f})\\n\")\n",
    "            \n",
    "                # have to loop through them again for the masks\n",
    "                for k, xc2, yc2, rc, rotc in detects[['INDEX', 'RA', 'DEC', 'R', 'ROTANG']]:\n",
    "                    if not j == k:\n",
    "                        pixels = w.wcs_world2pix(xc, yc, 0)\n",
    "                        reg.write(f'-ellipse({pixels[0]:.5f},{pixels[1]:.5f},'\n",
    "                                  f'{rc[0]:.3f},{rc[1]:.3f},{rotc:.3f})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xselect_pha(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_cl.evt', recursive=True)\n",
    "    \n",
    "    if len(files) < 1:\n",
    "        return name\n",
    "    \n",
    "    # write one background region for each observation\n",
    "    for f_in in files:\n",
    "        \n",
    "        obs_id = f_in.split('/')[-2]\n",
    "        \n",
    "        # create the background xselect call first\n",
    "        if not os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_bkg.reg'):\n",
    "            continue\n",
    "    \n",
    "        # write background xsel.in\n",
    "        with open(f'{outpath}/{name}/spec_files/{obs_id}_bkg.in', 'w') as f:\n",
    "            # this is the session name... specify random letters to run many at once.\n",
    "            f.writelines(f'{obs_id}\\n')\n",
    "            f.writelines('read events\\n')\n",
    "            # set the data directory\n",
    "            f.writelines('/'.join(f_in.split('/')[:5]) + '\\n')\n",
    "            # first entry\n",
    "            f.writelines('/'.join(f_in.split('/')[5:]) + '\\n')\n",
    "            f.writelines('yes\\n')\n",
    "            f.writelines(f'filter region {outpath}/{name}/spec_files/{obs_id}_bkg.reg\\n')\n",
    "            f.writelines('extract spectrum\\n')\n",
    "            f.writelines(f'save spectrum {outpath}/{name}/spec_files/{obs_id}_bkg_pc.pha\\n')\n",
    "            if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_bkg_pc.pha'):\n",
    "                f.writelines('yes\\n')\n",
    "            f.writelines('exit\\n')\n",
    "            f.writelines('no\\n')\n",
    "        \n",
    "        # log the output\n",
    "        log_file = f'{outpath}/{name}/spec_files/{obs_id}_bkg_pha.log'\n",
    "                         \n",
    "        # call xselect\n",
    "        check_exe('xselect')\n",
    "        os.system(f'xselect < {outpath}/{name}/spec_files/{obs_id}_bkg.in > {log_file}')\n",
    "        \n",
    "        # now we do all the sources.\n",
    "        for j in detects['INDEX']:\n",
    "            if not os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg'):\n",
    "                continue\n",
    "                \n",
    "            # write source xsel.in\n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}.in', 'w') as f:\n",
    "                # this is the session name... specify random letters to run many at once.\n",
    "                f.writelines(f'{obs_id}_{j}\\n')\n",
    "                f.writelines('read events\\n')\n",
    "                # set the data directory\n",
    "                f.writelines('/'.join(f_in.split('/')[:5]) + '\\n')\n",
    "                # first entry\n",
    "                f.writelines('/'.join(f_in.split('/')[5:]) + '\\n')\n",
    "                f.writelines('yes\\n')\n",
    "                f.writelines(f'filter region {outpath}/{name}/spec_files/{obs_id}_{j}.reg\\n')\n",
    "                f.writelines('extract spectrum\\n')\n",
    "                f.writelines(f'save spectrum {outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha\\n')\n",
    "                if os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'):\n",
    "                    f.writelines('yes\\n')\n",
    "                f.writelines('exit\\n')\n",
    "                f.writelines('no\\n')\n",
    "                \n",
    "            # log the output\n",
    "            log_file = f'{outpath}/{name}/spec_files/{obs_id}_{j}_pha.log'\n",
    "                \n",
    "            # call xselect\n",
    "            os.system(f'xselect < {outpath}/{name}/spec_files/{obs_id}_{j}.in > {log_file}')\n",
    "#             proc = subprocess.Popen(f'xselect < {outpath}/{name}/spec_files/{obs_id}_{j}.in',\n",
    "#                                 shell=True, preexec_fn=set_env)\n",
    "#             proc.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_arf(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    # find the event files\n",
    "    files = glob(f'{outpath}/{name}/reduced/**/*xpcw[1-4]po_ex.img', recursive=True)\n",
    "    \n",
    "    if len(files) < 1:\n",
    "        return name\n",
    "    \n",
    "    check_exe('xrtmkarf')\n",
    "    \n",
    "    for f_in in files:\n",
    "        \n",
    "        obs_id = f_in.split('/')[-2]\n",
    "        # now we have to loop through the detections\n",
    "        for j, ra, dec in detects[['INDEX', 'RA', 'DEC']]:\n",
    "            # check that we have the files\n",
    "            if not os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'):\n",
    "                continue\n",
    "            else:\n",
    "                pha = f'{outpath}/{name}/spec_files/{obs_id}_{j}_pc.pha'\n",
    "    \n",
    "            # we cannot use the X/Y position in the catalog because it was detected in \n",
    "            # the combined frame. We need to use the RA/DEC and then find the pixel positions\n",
    "            # in the individual frames. Lame.\n",
    "            # WCS info to convert world coords to pixels \n",
    "            hdr = fits.getheader(f_in)\n",
    "            w = wcs.WCS(hdr)\n",
    "            pixels = w.wcs_world2pix(ra, dec, 0)\n",
    "    \n",
    "            cmd = (f'xrtmkarf phafile={pha} srcx={pixels[0]} srcy={pixels[1]} '\n",
    "                   f'outfile={outpath}/{name}/spec_files/{obs_id}_{j}_pc.arf '\n",
    "                   f'psfflag=yes extended=yes expofile={f_in} clobber+')\n",
    "\n",
    "            # log the output\n",
    "            log_file = f'{outpath}/{name}/spec_files/{obs_id}_{j}_arf.log'\n",
    "\n",
    "            # call\n",
    "            print(cmd)\n",
    "            #os.system(f'{cmd} > {log_file}')\n",
    "            \n",
    "            args = shlex.split(f'{cmd} > {log_file}')\n",
    "            out = \"\"\n",
    "\n",
    "            with subprocess.Popen(args,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          universal_newlines=True) as proc:\n",
    "\n",
    "                proc.wait()\n",
    "                out = proc.stdout.read()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_spectra(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    # get a list of the reduced obs.\n",
    "    reduc = get_immediate_subdirectories(f'{outpath}/{name}/reduced')\n",
    "    reduc_ids = [r.split('/')[-1] for r in reduc]\n",
    "    \n",
    "    if len(reduc) < 1:\n",
    "        return\n",
    "    \n",
    "    check_exe('addascaspec')\n",
    "    # we are gonna need to change directories\n",
    "    wd = os.getcwd()\n",
    "    \n",
    "    # now we do all the sources.\n",
    "    for j in detects['INDEX']:\n",
    "        # make sure we have that source.\n",
    "        obs_id = reduc_ids[0]\n",
    "        if not os.path.isfile(f'{outpath}/{name}/spec_files/{obs_id}_{j}.reg'):\n",
    "            continue\n",
    "            \n",
    "        # remove files if they are already there.\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc.pha'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_pc.pha')\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc.arf'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_pc.arf')\n",
    "        if os.path.isfile(f'{outpath}/{name}/spec_files/{j}_bkg.pha'):\n",
    "            os.remove(f'{outpath}/{name}/spec_files/{j}_bkg.pha')    \n",
    "        \n",
    "        # build the file lists:  \n",
    "        spectra = [f'{obs_id}_{j}_pc.pha' for obs_id in reduc_ids]\n",
    "        bkgs = [f'{obs_id}_bkg_pc.pha' for obs_id in reduc_ids]\n",
    "        arfs = [f'{obs_id}_{j}_pc.arf' for obs_id in reduc_ids]  \n",
    "        \n",
    "        # the rmfs are harder to build\n",
    "        rmfs = []\n",
    "        for obs_id in reduc_ids:\n",
    "            with open(f'{outpath}/{name}/spec_files/{obs_id}_{j}_arf.log', 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for l in lines:\n",
    "                    if '/opt/caldb//data/swift/xrt/cpf/rmf/' in l:\n",
    "                        rmfs.append(l.split(\"'\")[1])\n",
    "                \n",
    "        # have to write the file list to pass to the spectrum combiner.\n",
    "        with open(f'{outpath}/{name}/spec_files/{j}.list', 'w') as f:\n",
    "            f.writelines(f'{\" \".join(spectra)}\\n')\n",
    "            f.writelines(f'{\" \".join(bkgs)}\\n')\n",
    "            f.writelines(f'{\" \".join(arfs)}\\n')\n",
    "            f.writelines(f'{\" \".join(rmfs)}\\n')\n",
    "        \n",
    "        # log the output\n",
    "        log_file = f'{j}_addascaspec.log'\n",
    "\n",
    "        cmd = f'addascaspec {j}.list {j}_pc.pha {j}_pc.arf {j}_bkg.pha'\n",
    "                         \n",
    "        # call\n",
    "#         print(cmd)\n",
    "        os.chdir(f'{outpath}/{name}/spec_files/')\n",
    "        os.system(f'{cmd} > {log_file}')\n",
    "                         \n",
    "        # do some other stuff -- add keywords to header\n",
    "#         os.system(f'fparkey value={j}_pc.arf fitsfile={j}_pc.pha+1 keyword=ANCRFILE')\n",
    "#         os.system(f'fparkey value={j}_bkg.pha fitsfile={j}_pc.pha+1 keyword=BACKFILE')\n",
    "#         os.system(f'fparkey value={rmfs[0]} fitsfile={j}_pc.pha+1 keyword=RESPFILE')\n",
    "                         \n",
    "        # group the counts\n",
    "        cnts = 10\n",
    "        cmd = (f\"grppha infile='{j}_pc.pha' outfile='{j}_pc_{cnts}cts.pha '\n",
    "               f\"chatter=0 comm='bad 1-31 & group min {cnts} & exit' clob+\")\n",
    "        args = shlex.split(cmd)\n",
    "        out = \"\"\n",
    "\n",
    "        with subprocess.Popen(args,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          universal_newlines=True) as proc:\n",
    "\n",
    "            proc.wait()\n",
    "            out = proc.stdout.read()\n",
    "\n",
    "        os.chdir(wd)\n",
    "\n",
    "#     return out, new_10cts_pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xspec_scripts(name, outpath):\n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    \n",
    "    # we are gonna need to change directories below\n",
    "    wd = os.getcwd()\n",
    "    os.chdir(f'{outpath}/{name}/spec_files/')\n",
    "    \n",
    "    # now we have to loop through the detections\n",
    "    for j in detects['INDEX']:\n",
    "        if not os.path.isfile(f'{j}_pc_{cnts}cts_xspec.in'):\n",
    "            continue\n",
    "        else:\n",
    "            source_xspec_in = f'{j}_pc_{cnts}cts_xspec.in'\n",
    "    \n",
    "        # build the command and call it\n",
    "        cmd = f\"xspec - {source_xspec_in}\"\n",
    "        args = shlex.split(cmd)\n",
    "        out = \"\"\n",
    "\n",
    "        with subprocess.Popen(args,\n",
    "                              stdout=subprocess.PIPE,\n",
    "                              universal_newlines=True) as proc:\n",
    "\n",
    "            try:\n",
    "                proc.wait(timeout=5)\n",
    "                out = proc.stdout.read()\n",
    "\n",
    "                #Read the fluxes and norms from the stdout\n",
    "                photon_flux = {}\n",
    "                energy_flux = {}\n",
    "\n",
    "                norms = []\n",
    "\n",
    "                outlines = out.split('\\n')\n",
    "                for line in outlines:\n",
    "                    if \"Model Flux\" in line:\n",
    "                        band_low = line.split(\" \")[8].split(\"(\")[1]\n",
    "                        band_high = line.split(\" \")[10]\n",
    "                        photons = float(line.split(\" \")[3])\n",
    "                        band = band_low + \"-\" + band_high\n",
    "                        photon_flux[band] = photons\n",
    "\n",
    "                        energy = float(line.split(\" \")[5].split(\"(\")[1])\n",
    "                        energy_flux[band] = energy\n",
    "                    elif \"mekal\" in line and \"norm\" in line:\n",
    "                        #the norm will be two index before the +/- sign\n",
    "\n",
    "                        pm_index = line.split(\" \").index(\"+/-\")\n",
    "                        norms.append(line.split(\" \")[pm_index - 2])\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    #Assuming the current script format, this is the one we want\n",
    "                    #This is with PE Absorption\n",
    "                goodnorm = float(norms[1])\n",
    "\n",
    "                #Get the index of the line containing the sigmas\n",
    "                conf_index = outlines.index(\" Parameter   Confidence Range (1)\")\n",
    "                sigma_line = outlines[conf_index + 1]\n",
    "                sigma_low = float(sigma_line.split(\" \")[-1].split(\"(\")[1].split(\",\")[0])\n",
    "                sigma_high = float(sigma_line.split(\" \")[-1].split(\"(\")[1].split()\",\")[1].split(\")\")[0])\n",
    "                sigma_av = (abs(sigma_low) + abs(sigma_high)) / 2\n",
    "\n",
    "                SN = goodnorm / sigma_av\n",
    "        #         print(out, energy_flux, photon_flux, goodnorm, sigma_av, SN)\n",
    "            except:\n",
    "                proc.kill()\n",
    "                out = proc.stdout.read()\n",
    "            os.chdir(wd)\n",
    "\n",
    "            xspec_out, en_flux, phot_flux, norm, sigma, SN = \\\n",
    "                                            out, energy_flux, photon_flux, goodnorm, sigma_av, SN\n",
    "\n",
    "            print(\"Energy Flux [ergs/cm^2/s]:\\n\", en_flux, '\\n',\n",
    "              \"Photon Flux [photons]:\\n\", phot_flux, '\\n', \"norm: \", norm,\n",
    "              '\\n', \"st. deviation: \", sigma, '\\n', \"S/N Ratio: \", SN,\n",
    "              '\\n')\n",
    "\n",
    "def mk_xspec_scripts(name, outpath, kT=5, z=0.1):\n",
    "    \n",
    "    # if there aren't detections, don't bother doing anything.\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect', hdu=1)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "    \n",
    "    # now we have to loop through the detections\n",
    "    for j, ra, dec in detects[['INDEX', 'RA', 'DEC']]:\n",
    "        if not os.path.isfile(f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts.pha'):\n",
    "            continue\n",
    "        else:\n",
    "            source_10cts_pha_name = f'{j}_pc_{cnts}cts.pha'\n",
    "\n",
    "        # get our nH value    \n",
    "        nH = runnh(ra, dec)[1]    \n",
    "\n",
    "        # here is the text we are going to write\n",
    "        text = [\"statistic chi\\n\",\n",
    "                f\"data 1:1 {source_10cts_pha_name}\\n\",\n",
    "#                 f'{outpath}/{name}/spec_files/{j}_pc.arf\\n',\n",
    "#                 f'{outpath}/{name}/spec_files/{j}_bkg.pha\\n',\n",
    "                \"ignore bad\\n\",\n",
    "                \"ignore 1\\n\",\n",
    "                'method leven 10 0.01\\n',\n",
    "                'abund angr\\n',\n",
    "                'xsect bcmc\\n',\n",
    "                'cosmo 70 0 0.70\\n',\n",
    "                'systematic 0\\n',\n",
    "                \"model  phabs*mekal\\n\",\n",
    "                f\"\\t{nH/1e22}, -1\\n\",\n",
    "                f\"\\t{kT}, -1\\n\",\n",
    "                \"\\t1\\n\", \n",
    "                \"\\t0.3\\n\",\n",
    "                f\"\\t{z}\\n\",\n",
    "                \"\\t1\\n\",\n",
    "                \"\\t0\\n\", \n",
    "                \"fit\\n\",\n",
    "                f'cpd {j}_pc_{cnts}cts.ps/cps\\n',\n",
    "                'setplot energy\\n',\n",
    "                'plot ldata\\n',\n",
    "#                 'rescale y 1.0e-4 0.05\\n',\n",
    "#                 f'label file {name}/spec_files/{j}_pc_{cnts}cts.pha',\n",
    "#                 'plot\\n',\n",
    "#                 'quit\\n',\n",
    "                'cpd none\\n',\n",
    "                \"error 1.0 7\\n\",\n",
    "                \"newpar 1 0\\n\",\n",
    "                \"fit\\n\",\n",
    "                \"flux 0.1 2.4\\n\",\n",
    "                \"flux 0.5 2\\n\",\n",
    "                \"flux 2 10\\n\" \n",
    "                \"exit\"\n",
    "               ]      \n",
    "        \n",
    "        #Write it to the script\n",
    "        with open(f'{outpath}/{name}/spec_files/{j}_pc_{cnts}cts_xspec.in', 'w') as script:\n",
    "            for line in text:\n",
    "                script.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'erg/s/cm2' contains multiple slashes, which is discouraged by the FITS standard [astropy.units.format.generic]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb01e6002d547949720bd844c51d44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "parallel_process(arr, create_bkg_regions, use_kwargs=True, n_jobs=6)\n",
    "parallel_process(arr, create_src_regions, use_kwargs=True, n_jobs=6)\n",
    "parallel_process(arr, xselect_pha, use_kwargs=True, n_jobs=6) # 2 hours\n",
    "parallel_process(arr, mk_arf, use_kwargs=True, n_jobs=6) # 41 minutes\n",
    "parallel_process(arr, combine_spectra, use_kwargs=True, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath ='./data_full'\n",
    "name = 'PSZ2_G075.08+19.83'\n",
    "# name = 'PSZ2_G139.62+24.18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bkg_regions(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_src_regions(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xselect_pha(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: RADECSYS= 'FK5 ' / default \n",
      "the RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xrtmkarf phafile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935004_1_pc.pha srcx=531.5609397463197 srcy=659.3074947408676 outfile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935004_1_pc.arf psfflag=yes extended=yes expofile=./data_full/PSZ2_G075.08+19.83/reduced/00049935004/sw00049935004xpcw3po_ex.img clobber+\n",
      "xrtmkarf phafile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935001_1_pc.pha srcx=550.8285707464637 srcy=675.4285690871842 outfile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935001_1_pc.arf psfflag=yes extended=yes expofile=./data_full/PSZ2_G075.08+19.83/reduced/00049935001/sw00049935001xpcw3po_ex.img clobber+\n",
      "xrtmkarf phafile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935005_1_pc.pha srcx=588.0864048322447 srcy=674.7261696429267 outfile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935005_1_pc.arf psfflag=yes extended=yes expofile=./data_full/PSZ2_G075.08+19.83/reduced/00049935005/sw00049935005xpcw3po_ex.img clobber+\n",
      "xrtmkarf phafile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935003_1_pc.pha srcx=610.973548351129 srcy=735.1374478505974 outfile=./data_full/PSZ2_G075.08+19.83/spec_files/00049935003_1_pc.arf psfflag=yes extended=yes expofile=./data_full/PSZ2_G075.08+19.83/reduced/00049935003/sw00049935003xpcw3po_ex.img clobber+\n"
     ]
    }
   ],
   "source": [
    "mk_arf(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addascaspec 1.list 1_pc.pha 1_pc.arf 1_bkg.pha\n",
      "grppha 1_pc.pha 1_pc_20cts.pha comm=\"bad 1-31 & group min 20 & exit\" clob+\n"
     ]
    }
   ],
   "source": [
    "combine_spectra(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_xspec_scripts(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy Flux [ergs/cm^2/s]:\n",
      " {'0.10000-2.4000': 7.6111e-13, '0.50000-2.0000': 4.6759e-13, '2.0000-10.000': 6.6507e-13} \n",
      " Photon Flux [photons]:\n",
      " {'0.10000-2.4000': 0.00087775, '0.50000-2.0000': 0.00029207, '2.0000-10.000': 0.00010802} \n",
      " norm:  0.00116974 \n",
      " st. deviation:  0.000113739 \n",
      " S/N Ratio:  10.284423109047909 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we are gonna need to change directories below\n",
    "wd = os.getcwd()\n",
    "os.chdir(f'{outpath}/{name}/spec_files/')\n",
    "\n",
    "cmd = \"xspec - 1_pc_10cts_xspec.in\"\n",
    "args = shlex.split(cmd)\n",
    "out = \"\"\n",
    "\n",
    "with subprocess.Popen(args,\n",
    "                      stdout=subprocess.PIPE,\n",
    "                      universal_newlines=True) as proc:\n",
    "\n",
    "    try:\n",
    "        proc.wait(timeout=5)\n",
    "        out = proc.stdout.read()\n",
    "        #Read the fluxes and norms from the stdout\n",
    "        photon_flux = {}\n",
    "        energy_flux = {}\n",
    "\n",
    "        norms = []\n",
    "\n",
    "        outlines = out.split('\\n')\n",
    "        for line in outlines:\n",
    "            if \"Model Flux\" in line:\n",
    "                band_low = line.split(\" \")[8].split(\"(\")[1]\n",
    "                band_high = line.split(\" \")[10]\n",
    "                photons = float(line.split(\" \")[3])\n",
    "                band = band_low + \"-\" + band_high\n",
    "                photon_flux[band] = photons\n",
    "\n",
    "                energy = float(line.split(\" \")[5].split(\"(\")[1])\n",
    "                energy_flux[band] = energy\n",
    "            elif \"mekal\" in line and \"norm\" in line:\n",
    "                #the norm will be two index before the +/- sign\n",
    "\n",
    "                pm_index = line.split(\" \").index(\"+/-\")\n",
    "                norms.append(line.split(\" \")[pm_index - 2])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            #Assuming the current script format, this is the one we want\n",
    "            #This is with PE Absorption\n",
    "        goodnorm = float(norms[1])\n",
    "\n",
    "        #Get the index of the line containing the sigmas\n",
    "        conf_index = outlines.index(\" Parameter   Confidence Range (1)\")\n",
    "        sigma_line = outlines[conf_index + 1]\n",
    "        sigma_low = float(sigma_line.split(\" \")[-1].split(\"(\")[1].split(\n",
    "            \",\")[0])\n",
    "        sigma_high = float(sigma_line.split(\" \")[-1].split(\"(\")[1].split(\n",
    "            \",\")[1].split(\")\")[0])\n",
    "        sigma_av = (abs(sigma_low) + abs(sigma_high)) / 2\n",
    "\n",
    "        SN = goodnorm / sigma_av\n",
    "#         print(out, energy_flux, photon_flux, goodnorm, sigma_av, SN)\n",
    "    except:\n",
    "        proc.kill()\n",
    "        out = proc.stdout.read()\n",
    "    os.chdir(wd)\n",
    "    \n",
    "    xspec_out, en_flux, phot_flux, norm, sigma, SN = out, energy_flux, photon_flux, goodnorm, sigma_av, SN\n",
    "    \n",
    "    print(\"Energy Flux [ergs/cm^2/s]:\\n\", en_flux, '\\n',\n",
    "      \"Photon Flux [photons]:\\n\", phot_flux, '\\n', \"norm: \", norm,\n",
    "      '\\n', \"st. deviation: \", sigma, '\\n', \"S/N Ratio: \", SN,\n",
    "      '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xspec', '<', './data_full/PSZ2_G075.08+19.83/spec_files/1_pc_10cts_xspec.in']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
