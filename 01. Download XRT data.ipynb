{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "\n",
    "from utilities import parallel_process, system_call, redshifts_from_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog(ra, dec, name, outpath, table='swiftmastr', oformat='fits'):\n",
    "\n",
    "    # build the command\n",
    "    cmd = (f'./browse_extract_wget.pl table={table} position={ra},{dec} '\n",
    "           f'outfile={outpath}/{name}/{name}xrt.fits format={oformat} radius=10')\n",
    "\n",
    "    if not os.path.isdir(f'{outpath}/{name}'):\n",
    "        os.makedirs(f'{outpath}/{name}')\n",
    "    \n",
    "#     print(cmd)\n",
    "    stdout, stderr = system_call(cmd, shlexify=False)\n",
    "\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(name, outpath, overwrite=False):\n",
    "\n",
    "    # at least one file was 0 bytes... \n",
    "    try:\n",
    "        cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "    except IndexError:\n",
    "        os.remove(f'{outpath}/{name}/{name}xrt.fits')\n",
    "        try:\n",
    "            os.remove(f'{outpath}/{name}/{name}.info')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        os.rmdir(f'{outpath}/{name}')\n",
    "        return\n",
    "\n",
    "    for i in range(cat.shape[0]):\n",
    "        obsid = cat['obsid'][i]\n",
    "        if os.path.isdir(f'{outpath}/{name}/{obsid}') and not overwrite: # this only downloads new observations\n",
    "            continue\n",
    "        else:\n",
    "            print(f'new observations for {name}!')\n",
    "        t = Time(cat['start_time'][i], format='mjd')\n",
    "        y, m = t.iso.split('-')[:2]\n",
    "\n",
    "        wget_base = (f'wget -P {outpath}/{name} -q -nH --no-check-certificate --cut-dirs=5 '\n",
    "                '-r -l0 -c -nc -np -R \"index*\" -erobots=off --retr-symlinks '\n",
    "                f'https://heasarc.gsfc.nasa.gov/FTP/swift/data/obs/{y}_{m}/')\n",
    "             \n",
    "        for prod in ['xrt', 'auxil', 'log']:\n",
    "            wget = f'{wget_base}{obsid}/{prod}/'\n",
    "            stdout, stderr = system_call(wget, shlexify=False)\n",
    "#             os.system(wget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_info(outpath, idx, data):\n",
    "    target = data.iloc[idx]['NAME'].replace(' ', '_')\n",
    "    \n",
    "    if not os.path.isdir(f'{outpath}/{target}'):\n",
    "        return\n",
    "    \n",
    "    cols = data.columns.tolist()\n",
    "    vals = data.iloc[idx]\n",
    "    # convert the values into all strings\n",
    "    vals_str = [f'{i:.8}' if isinstance(i, float) else i for i in vals.values.tolist()]\n",
    "    with open(f'{outpath}/{target}/{target}.info', 'w') as f:\n",
    "        f.write(f'{\",\".join(cols)}\\n')\n",
    "        f.write(f'{\",\".join(vals_str)}\\n')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_values('NAME')\n",
    "\n",
    "data = redshifts_from_papers(data)\n",
    "\n",
    "outpath = './data_full_new'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), \n",
    "        'outpath':outpath, \n",
    "        'ra': ra,\n",
    "        'dec': dec} for n, ra, dec in zip(data['NAME'], data['RA'], data['DEC'])]\n",
    "\n",
    "parallel_process(arr, get_catalog, use_kwargs=True, n_jobs=6)\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "parallel_process(arr, get_files, use_kwargs=True, n_jobs=6)\n",
    "\n",
    "for i, n in enumerate(data['NAME']):\n",
    "    write_info(outpath, i, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
