{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "                \n",
    "# parallel processor\n",
    "from utilities import parallel_process, check_exe, system_call\n",
    "from utilities import get_immediate_subdirectories, get_immediate_subfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows us to run the pipeline not interactively. \n",
    "os.environ['HEADASNOQUERY'] = ''\n",
    "os.environ['HEADASPROMPT'] = '/dev/null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(name, outpath, overwrite=False):\n",
    "\n",
    "    if not os.path.isdir(f'{outpath}/{name}'):\n",
    "        return\n",
    "    \n",
    "    if not check_exe('xrtpipeline', verb=False):\n",
    "        return\n",
    "    \n",
    "    # get a list of the XRT obs. \n",
    "    obs = get_immediate_subdirectories(f'{outpath}/{name}')\n",
    "        \n",
    "    # if there aren't any observations, keep going\n",
    "    if not len(obs):\n",
    "        return\n",
    "    \n",
    "    if not os.path.isdir(f'{outpath}/{name}/reduced'):\n",
    "        os.makedirs(f'{outpath}/{name}/reduced')\n",
    "    \n",
    "    # get a list of the reduced obs.\n",
    "    reduc = get_immediate_subdirectories(f'{outpath}/{name}/reduced')\n",
    "    \n",
    "    for ob_dir in obs:\n",
    "        ob_id = ob_dir.split('/')[-1]\n",
    "        reduc_ids = [r.split('/')[-1] for r in reduc]\n",
    "        evts = False\n",
    "        expm = False\n",
    "        if ob_id == 'reduced':\n",
    "            continue\n",
    "        elif ob_id == 'spec_files':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                for f in get_immediate_subfiles(f'{outpath}/{name}/reduced/{ob_id}'):\n",
    "                    if 'po_cl.evt' in f:\n",
    "                        evts = True\n",
    "                    elif 'po_ex.img' in f:\n",
    "                        expm = True\n",
    "                    else:\n",
    "                        continue    \n",
    "                if evts and expm and not overwrite:\n",
    "                    continue\n",
    "            except FileNotFoundError: # happens when nothing has been reduced\n",
    "                pass\n",
    "                    \n",
    "        cmd = (f'xrtpipeline indir={ob_dir} outdir={outpath}/{name}/reduced/{ob_id} steminputs=sw{ob_id} '\n",
    "                    'srcra=OBJECT srcdec=OBJECT datamode=PC cleanup=yes vigflag=yes clobber=yes ')\n",
    "        \n",
    "        stdout, stderr = system_call_env(cmd, shlexify=False)\n",
    "        \n",
    "        # log the output\n",
    "        log_file = f'{outpath}/{name}/reduced/{ob_id}_reduce.log'\n",
    "        with open(log_file, 'w') as f:\n",
    "            f.writelines(stdout)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    '''This has been rolled into the main function above''' \n",
    "    \n",
    "    PSZs = get_immediate_subdirectories('./data_full')\n",
    "    for psz in tqdm_notebook(PSZs):\n",
    "        # get a list of the XRT obs. \n",
    "            for ob_dir in get_immediate_subdirectories(psz):\n",
    "                # check for events and exposure map\n",
    "                evts = False\n",
    "                expm = False\n",
    "                if ob_id == 'reduced':\n",
    "                    continue\n",
    "                else:\n",
    "                    for f in get_immediate_subfiles(f'{psz}/reduced/{ob_id}'):\n",
    "                        if 'po_cl.evt' in f:\n",
    "                            evts = True\n",
    "                        elif 'po_ex.img' in f:\n",
    "                            expm = True\n",
    "                        else:\n",
    "                            continue\n",
    "                \n",
    "                    if not evts and expm:\n",
    "                        print(f'{psz}/reduced/{ob_id} NOT VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Running the xrtpipeline or really any ftool doesn't always work well when run in parallel. \n",
    "\n",
    "You should run everything once (or twice) with n_jobs=6 (or some number > 1) and then a final\n",
    "time with n_jobs=1. This makes sure that the majority of the work gets done in parallel, and then\n",
    "things are finallized serially. This notebook won't redo work, so if the data products are created\n",
    "during the parallel processing, it won't be redone when run serially. \n",
    "\n",
    "Another issue is that some of the observations are in \"window timing\" or WT mode. The pipeline\n",
    "script only looks at data in \"photon counting\" or PC mode. This causes a lot observations to be run\n",
    "but no reduced data prodcuts will be produced. If you look at the logs, it will say that no events files\n",
    "are found in the directory tree. If you look at the downloaded data, you will see a bunch of files with \n",
    "\"wt\" in them and no \"pc\" files.\n",
    "\n",
    "This notebook considers those observations as \"not done\" so it tries to redo them. That means that every\n",
    "time you run this notebook it will find work to do, even though those observations aren't any good to us.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_values('NAME')\n",
    "\n",
    "outpath = './data_full_new'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath, 'overwrite':False} for n in data['NAME']]\n",
    "parallel_process(arr, run_pipeline, use_kwargs=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outpath = './data_full_new'\n",
    "# name = 'PSZ2_G110.28-87.48'\n",
    "# run_pipeline(name, outpath, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
