{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import aplpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from astropy.table import Table\n",
    "from astropy.io.fits import getheader\n",
    "from astropy.convolution import convolve\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add extra code to run things in parallel.\n",
    "The combining exposure maps takes a REALLY long time. So I added this bit so I can run it all in parallel.\n",
    "\n",
    "You don't need to run any of this if you don't want to run things in paralle. I'll try to comment out code at the bottom so you can run things in parallel or not depending on what you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_process(array, function, n_jobs=None, use_kwargs=False, front_num=0):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the \n",
    "                parallel job. This can be useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    #We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "    #If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        return [function(**a) if use_kwargs else function(a) for a in tqdm_notebook(array[front_num:])]\n",
    "    #Assemble the workers\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        #Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': False,\n",
    "            'leave': True\n",
    "        }\n",
    "        #Print out the progress as tasks complete\n",
    "        for f in tqdm_notebook(as_completed(futures), **kwargs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_contours(name, outpath):\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_events.fits'):\n",
    "        return\n",
    "\n",
    "    # start ds9\n",
    "    p = subprocess.Popen(['ds9', f'{outpath}/{name}/{name}_events.fits'])\n",
    "\n",
    "    ds9_cmds = ['xpaset -p ds9 bin factor 8',\n",
    "                \"xpaset -p ds9 bin filter 'pi=50:200'\",\n",
    "                'xpaset -p ds9 smooth 3',\n",
    "                'xpaset -p ds9 contour yes',\n",
    "                'xpaset -p ds9 contour smooth 1',\n",
    "                'xpaset -p ds9 contour color white',\n",
    "                'xpaset -p ds9 contour convert',\n",
    "                f'xpaset -p ds9 regions save {outpath}/{name}/{name}_contours.reg',\n",
    "                'xpaset -p ds9 exit']\n",
    "\n",
    "    # wait for ds9 to start\n",
    "    print(\"waiting 2 seconds for ds9 to start\")\n",
    "    sleep(2)\n",
    "\n",
    "    for cmd in ds9_cmds:\n",
    "        os.system(cmd)\n",
    "\n",
    "    p.wait()\n",
    "    p.kill()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_contours2(name, outpath):\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200_bl8.fits'):\n",
    "        return\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200_bl8.det'):\n",
    "        print('No sources detected -- reverting to old contours')\n",
    "        mk_contours(name)\n",
    "        return\n",
    "\n",
    "    # start ds9\n",
    "    p = subprocess.Popen(['ds9', f'{outpath}/{name}/{name}_img_50-200_bl8.fits'])\n",
    "\n",
    "    # figure out the contour levels\n",
    "    with open(f'{outpath}/{name}/{name}_img_50-200_bl8.det', 'r') as f:\n",
    "        for l in f.readlines():\n",
    "            if 'Back' in l:\n",
    "                background = float(l.split(':')[-1])\n",
    "                break\n",
    "\n",
    "    # now scale the background appropriately -- 5 sigma\n",
    "    cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "    exp_time = cat['xrt_exposure'].sum()\n",
    "\n",
    "    # 8x8 binning\n",
    "    min_pixel = background * 8 * 8 * exp_time * 5\n",
    "\n",
    "    # now figure out the top level\n",
    "    img = fits.getdata(f'{outpath}/{name}/{name}_img_50-200_bl8.fits')\n",
    "    # smooth the image\n",
    "    kernal = Gaussian2DKernel(stddev=1)\n",
    "    smoothed_img = convolve(img, kernal)\n",
    "    max_pixel = smoothed_img.max()\n",
    "\n",
    "    # generate contour levels using a sqrt scale\n",
    "    # i got this from the ds9 source code\n",
    "    nlvls = 5\n",
    "    lvls = np.linspace(0, 1, nlvls) / (nlvls - 1)\n",
    "    lvls = lvls**2 * (max_pixel - min_pixel) + min_pixel\n",
    "    lvls_str = [str(i) for i in lvls]\n",
    "    lvls_str = ' '.join(lvls_str)\n",
    "\n",
    "    ds9_cmds = ['xpaset -p ds9 smooth 3',\n",
    "                'xpaset -p ds9 contour yes',\n",
    "                'xpaset -p ds9 contour nlevels 5',\n",
    "                'xpaset -p ds9 contour levels \"{{{}}}\"'.format(lvls_str),\n",
    "                'xpaset -p ds9 contour smooth 1',\n",
    "                'xpaset -p ds9 contour color white',\n",
    "                'xpaset -p ds9 contour convert',\n",
    "                f'xpaset -p ds9 regions save {outpath}/{name}/{name}_contours.reg',\n",
    "                'xpaset -p ds9 exit']\n",
    "\n",
    "    # wait for ds9 to start\n",
    "    print(\"waiting 2 seconds for ds9 to start\")\n",
    "    sleep(2)\n",
    "\n",
    "    for cmd in ds9_cmds:\n",
    "        os.system(cmd)\n",
    "\n",
    "    p.wait()\n",
    "    p.kill()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_contours(name, outpath):\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_PS1stack_i.fits'):\n",
    "        return\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_contours.reg'):\n",
    "        return\n",
    "\n",
    "    cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "\n",
    "    exp_time = cat['xrt_exposure'].sum()\n",
    "    text = f'exp time: {exp_time:.2}s'\n",
    "\n",
    "    gc = aplpy.FITSFigure(f'{outpath}/{name}/{name}_PS1stack_i.fits')\n",
    "    gc.show_rgb(f'{outpath}/{name}/{name}_PS1stack_irg.tiff')\n",
    "    try:\n",
    "        gc.show_regions(f'{outpath}/{name}/{name}_contours.reg')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # add exposure info\n",
    "    xo, yo = (80, 80)\n",
    "    plt.text(xo + 2, yo + 2, text, color='black', fontsize=18)\n",
    "    plt.text(xo, yo, text, color='white', fontsize=18)\n",
    "\n",
    "    gc.save(f'{outpath}/{name}/{name}_contours.png')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_contours2(name, outpath):\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200_bl8.fits'):\n",
    "        return\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200_bl8.det'):\n",
    "\n",
    "        print('No sources detected -- reverting to old contours')\n",
    "        cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "\n",
    "        exp_time = cat['xrt_exposure'].sum()\n",
    "        text = f'exp time: {exp_time:.2}s'\n",
    "\n",
    "        gc = aplpy.FITSFigure(f'{outpath}/{name}/{name}_img_50-200_bl8.fits')\n",
    "        gc.show_grayscale()\n",
    "        try:\n",
    "            gc.show_regions(f'{outpath}/{name}/{name}_contours.reg')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # add exposure info\n",
    "        xo, yo = (80, 80)\n",
    "        plt.text(xo + 2, yo + 2, text, color='black', fontsize=18)\n",
    "        plt.text(xo, yo, text, color='white', fontsize=18)\n",
    "\n",
    "        gc.save(f'{outpath}/{name}/{name}_XRT_contours.png')\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "    # figure out the contour levels\n",
    "    with open(f'{outpath}/{name}/{name}_img_50-200_bl8.det', 'r') as f:\n",
    "        for l in f.readlines():\n",
    "            if 'Back' in l:\n",
    "                background = float(l.split(':')[-1])\n",
    "                break\n",
    "\n",
    "    # now scale the background appropriately -- 5 sigma\n",
    "    cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "    exp_time = cat['xrt_exposure'].sum()\n",
    "\n",
    "    # 8x8 binning\n",
    "    min_pixel = background * 8 * 8 * exp_time * 5\n",
    "\n",
    "    # now figure out the top level\n",
    "    img = fits.getdata(f'{outpath}/{name}/{name}_img_50-200_bl8.fits')\n",
    "    # smooth the image\n",
    "    kernal = Gaussian2DKernel(stddev=1, x_size=3, y_size=3)\n",
    "    smoothed_img = convolve(img, kernal)\n",
    "    max_pixel = smoothed_img.max()\n",
    "\n",
    "    # generate contour levels using a sqrt scale\n",
    "    # i got this from the ds9 source code\n",
    "    nlvls = 5\n",
    "    lvls = np.linspace(0, 1, nlvls) / (nlvls - 1)\n",
    "    lvls = lvls**2 * (max_pixel - min_pixel) + min_pixel\n",
    "    lvls_str = [str(i) for i in lvls]\n",
    "    lvls_str = ' '.join(lvls_str)\n",
    "\n",
    "    cat = fits.getdata(f'{outpath}/{name}/{name}xrt.fits')\n",
    "\n",
    "    exp_time = cat['xrt_exposure'].sum()\n",
    "    text = f'exp time: {exp_time:.2}s'\n",
    "\n",
    "    gc = aplpy.FITSFigure(f'{outpath}/{name}/{name}_img_50-200_bl8.fits')\n",
    "    gc.show_grayscale()\n",
    "    gc.show_contour(smooth=3, levels=lvls, cmap='viridis')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # add exposure info\n",
    "    xo, yo = (80, 80)\n",
    "    plt.text(xo + 2, yo + 2, text, color='black', fontsize=18)\n",
    "    plt.text(xo, yo, text, color='white', fontsize=18)\n",
    "\n",
    "    gc.save(f'{outpath}/{name}/{name}_XRT_contours.png')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sources(name, outpath):\n",
    "    # check for files\n",
    "    # check for detections\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "    else:\n",
    "        return\n",
    "    # events image\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_img_50-600.fits'):\n",
    "        evnts = f'{outpath}/{name}/{name}_img_50-600.fits'\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    # check for imaging -- sdss first\n",
    "    if os.path.isfile(f'{outpath}/{name}/{name}_DECaLSstack_r.fits'):\n",
    "        survey = 'DECaLS'\n",
    "        optimage = True\n",
    "        img = f'{outpath}/{name}/{name}_DECaLSstack_r.fits'\n",
    "    elif os.path.isfile(f'{outpath}/{name}/{name}_SDSSstack_i.fits'):\n",
    "        survey = 'SDSS'\n",
    "        optimage = True\n",
    "        img = f'{outpath}/{name}/{name}_SDSSstack_i.fits'\n",
    "    elif os.path.isfile(f'{outpath}/{name}/{name}_PS1stack_i.fits'):\n",
    "        survey = 'PS1'\n",
    "        optimage = True\n",
    "        img = f'{outpath}/{name}/{name}_PS1stack_i.fits'\n",
    "    else:\n",
    "        optimage = False   \n",
    "    \n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "    info = Table.read(f'{outpath}/{name}/{name}.info', format='ascii.fast_csv')\n",
    "    \n",
    "    \n",
    "    # show the figure\n",
    "    gc = aplpy.FITSFigure(evnts, figsize=(10, 10))\n",
    "    gc.show_grayscale(vmin=0, pmax=100, stretch='linear', interpolation='none')\n",
    "    \n",
    "    # add all the sources -- the float is the pixscale in deg\n",
    "    r1 = detects['R'].data[:,0] * 6.548089E-04\n",
    "    r2 = detects['R'].data[:,1] * 6.548089E-04\n",
    "    gc.show_ellipses(detects['RA'], detects['DEC'], r1, r2, detects['ROTANG'], \n",
    "                     coords_frame='world', edgecolor='cyan')\n",
    "\n",
    "    # add PSZ info and circles\n",
    "    gc.show_circles(info['RA'], info['DEC'], 2 / 60,\n",
    "                    linestyle='--', edgecolor='#e24a33', facecolor='none',\n",
    "                    path_effects=[pe.Stroke(linewidth=1.2, foreground='white'),\n",
    "                                  pe.Normal()])\n",
    "    gc.show_circles(info['RA'], info['DEC'], 5 / 60,\n",
    "                    linestyle='-', edgecolor='#e24a33', facecolor='none',\n",
    "                    path_effects=[pe.Stroke(linewidth=1.2, foreground='white'),\n",
    "                                  pe.Normal()])\n",
    "    gc.show_markers(info['RA'], info['DEC'],\n",
    "                    marker='*', s=150, layer='psz', edgecolor='#e24a33',\n",
    "                    path_effects=[pe.Stroke(linewidth=1.2,\n",
    "                                            foreground='white'), pe.Normal()])\n",
    "\n",
    "    # write the exposure time\n",
    "    exp_time = getheader(evnts)['EXPOSURE']\n",
    "    text = f'exp time: {exp_time:.2f}s'\n",
    "    xo, yo = (0.05, 0.05)\n",
    "    gc.add_label(xo, yo, text, relative=True, fontsize=18, color='white', horizontalalignment='left')\n",
    "\n",
    "    # write redshift\n",
    "    ztext = f'z: {info[\"REDSHIFT_PSZ2\"][0]:.3f}'\n",
    "    gc.add_label(xo, yo + 0.03, ztext, relative=True, fontsize=18, color='white', horizontalalignment='left')\n",
    "    \n",
    "    gc.save(f'{outpath}/{name}/{name}_XRT_vtp.png', dpi=90)\n",
    "\n",
    "    gc.close()\n",
    "    \n",
    "    ### optical imaging ###    \n",
    "    if optimage:\n",
    "        # make sure the links aren't broken\n",
    "        if os.path.exists(f'{outpath}/{name}/{name}_{survey}stack.jpg'):\n",
    "            ending = 'stack.jpg'\n",
    "        elif os.path.exists(f'{outpath}/{name}/{name}_{survey}stack_irg.tiff'):\n",
    "            ending = 'stack_irg.tiff'\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "        # show the figure\n",
    "        gc = aplpy.FITSFigure(img, figsize=(10, 10))\n",
    "        try:\n",
    "            gc.show_rgb(f'{outpath}/{name}/{name}_{survey}{ending}')\n",
    "        except FileNotFoundError:\n",
    "            gc.show_grayscale(stretch='arcsinh', pmin=1, pmax=98)\n",
    "            gc.set_theme('publication')\n",
    "\n",
    "        #gc.set_tick_labels_format(xformat='hh:mm:ss', yformat='dd:mm')\n",
    "        #gc.set_tick_labels_size('small')\n",
    "       \n",
    "        # add all the sources -- the float is the pixscale in deg\n",
    "        r1 = detects['R'].data[:,0] * 6.548089E-04\n",
    "        r2 = detects['R'].data[:,1] * 6.548089E-04\n",
    "        gc.show_ellipses(detects['RA'], detects['DEC'], r1, r2, detects['ROTANG'], \n",
    "                         coords_frame='world', edgecolor='cyan')\n",
    "\n",
    "        # add PSZ info and circles\n",
    "        gc.show_circles(info['RA'], info['DEC'], 2 / 60,\n",
    "                        linestyle='--', edgecolor='#e24a33', facecolor='none',\n",
    "                        path_effects=[pe.Stroke(linewidth=1.2, foreground='white'),\n",
    "                                      pe.Normal()])\n",
    "        gc.show_circles(info['RA'], info['DEC'], 5 / 60,\n",
    "                        linestyle='-', edgecolor='#e24a33', facecolor='none',\n",
    "                        path_effects=[pe.Stroke(linewidth=1.2, foreground='white'),\n",
    "                                      pe.Normal()])\n",
    "        gc.show_markers(info['RA'], info['DEC'],\n",
    "                        marker='*', s=150, layer='psz', edgecolor='#e24a33',\n",
    "                        path_effects=[pe.Stroke(linewidth=1.2,\n",
    "                                                foreground='white'), pe.Normal()])\n",
    "\n",
    "        # write the exposure time\n",
    "        gc.add_label(xo, yo, text, relative=True, fontsize=18, color='white', horizontalalignment='left')\n",
    "\n",
    "        # write redshift\n",
    "        gc.add_label(xo, yo + 0.03, ztext, relative=True, fontsize=18, color='white', horizontalalignment='left')\n",
    "        \n",
    "        gc.save(f'{outpath}/{name}/{name}_OP_vtp.png', dpi=90)\n",
    "\n",
    "        gc.close()\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "parallel_process(arr, show_sources, use_kwargs=True, n_jobs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
