{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, Column\n",
    "from tqdm import tqdm_notebook\n",
    "import tempfile\n",
    "from math import sqrt, sin, cos, pow\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.environ[\"HOME\"]}/Projects/planckClusters/catalogs')\n",
    "from load_catalogs import load_PSZcatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add extra code to run things in parallel.\n",
    "The combining exposure maps takes a REALLY long time. So I added this bit so I can run it all in parallel.\n",
    "\n",
    "You don't need to run any of this if you don't want to run things in paralle. I'll try to comment out code at the bottom so you can run things in parallel or not depending on what you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_process(array, function, n_jobs=None, use_kwargs=False, front_num=0):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the \n",
    "                parallel job. This can be useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    #We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "    #If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        [function(**a) if use_kwargs else function(a) for a in tqdm_notebook(array[front_num:])]\n",
    "        return \n",
    "    #Assemble the workers\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        #Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': False,\n",
    "            'leave': True\n",
    "        }\n",
    "        #Print out the progress as tasks complete\n",
    "        for f in tqdm_notebook(as_completed(futures), **kwargs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_detect(name, outpath, pp=None):                                       \n",
    "    ''' This uses the detect function as part of the ximage package. This tool was originally\n",
    "    written to work with SWIFT data. Because SWIFT was really designed to be a point source\n",
    "    observatory, this tool is pretty good at finding point sources.\n",
    "\n",
    "    I think we have replaced this function with the second detect function, below, which uses\n",
    "    a different tool, originally written to find extended sources in CHANDRA data. That seems\n",
    "    to be more of what we are trying to do, and it seems to have a similar performance.\n",
    "\n",
    "    '''                                                                        \n",
    "\n",
    "    with open(f'{outpath}/{name}/{name}_ximg_det.in', 'w') as f:\n",
    "        for eng in [200, 300, 400, 500, 600]:\n",
    "            if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}.fits'):\n",
    "                continue                                                       \n",
    "            f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl4.fits\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'fitsdet={{{outpath}/{name}/{name}_img_50-{eng}_bl4.det.fits}}\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'filedet={{{outpath}/{name}/{name}_img_50-{eng}_bl4.det}}\\n')\n",
    "                                                                               \n",
    "            f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl8.fits\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'fitsdet={{{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits}}\\n')\n",
    "            f.writelines('detect/snr_threshold=3/'\n",
    "                    f'filedet={{{outpath}/{name}/{name}_img_50-{eng}_bl8.det}}\\n')\n",
    "\n",
    "            # remove old files if they exist\n",
    "            if os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits'):\n",
    "                os.remove(f'{outpath}/{name}/{name}_img_50-{eng}_bl8.det.fits')\n",
    "\n",
    "        f.writelines('exit\\n')\n",
    "\n",
    "    # log output\n",
    "    log_file = f'{outpath}/{name}/{name}_ximg_det.log'\n",
    "\n",
    "    # call xselect\n",
    "    cmd = f'ximage < {outpath}/{name}/{name}_ximg_det.in > {log_file}'\n",
    "    if not pp:\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        pp.submit(call_cmd, cmd)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointInEllipse(xo, yo, xp, yp, d, D, angle):\n",
    "    #tests if a point[xp,yp] is within\n",
    "    #boundaries defined by the ellipse\n",
    "    #of center[x,y], diameter d D, and tilted at angle\n",
    "    \n",
    "    ## This is for the detect_vtp function #\n",
    "    \n",
    "    cosa = cos(angle)\n",
    "    sina = sin(angle)\n",
    "    \n",
    "    dd = d**2\n",
    "    DD = D**2\n",
    "\n",
    "    a = pow(cosa * (xp - xo) + sina * (yp - yo), 2)\n",
    "    b = pow(sina * (xp - xo) - cosa * (yp - yo), 2)\n",
    "    ellipse = (a / dd) + (b / DD)\n",
    "    \n",
    "    if ellipse <= 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vtpname(name, outpath):\n",
    "    # set up all the non-file-specific parameters                              \n",
    "    params = {}\n",
    "    params['limit'] = 1E-6\n",
    "    params['coarse'] = 5\n",
    "    params['maxiter'] = 10\n",
    "    params['clobber'] = 'yes'\n",
    "    params['verbose'] = 1\n",
    "\n",
    "    evts = f'{outpath}/{name}/{name}_events.fits'\n",
    "    expmap = f'{outpath}/{name}/{name}_exp.fits'\n",
    "\n",
    "    # check to make sure the files exist.\n",
    "    if not os.path.isfile(evts) and not os.path.isfile(expmap):\n",
    "        return 0\n",
    "                                                                               \n",
    "    # We are going to run vtpdetect twice... once with a low scale and once with a high(er) scale\n",
    "    params['regfile'] = f'{outpath}/{name}/{name}_vtp_low.reg'\n",
    "    params['log'] = f'{outpath}/{name}/{name}_vtp_low.log'\n",
    "    params['scale'] = 1\n",
    "    outfits = f'{outpath}/{name}/{name}_vtp_low.detect'\n",
    "    with open(f'{outpath}/{name}/{name}_vtp_low.in', 'w') as f:\n",
    "        # build the cmd\n",
    "        cmd = f'vtpdetect {evts}[pi=50:600] {expmap} {outfits} '\n",
    "        for param, value in list(params.items()):\n",
    "            cmd += f'{param}={value} '\n",
    "        f.writelines(f'{cmd}\\n')\n",
    "\n",
    "    os.system(cmd)\n",
    "\n",
    "    # now for the higher level\n",
    "    params['regfile'] = f'{outpath}/{name}/{name}_vtp_high.reg'\n",
    "    params['log'] = f'{outpath}/{name}/{name}_vtp_high.log'\n",
    "    params['scale'] = 1.8\n",
    "    outfits = f'{outpath}/{name}/{name}_vtp_high.detect'\n",
    "    with open(f'{outpath}/{name}/{name}_vtp_high.in', 'w') as f:\n",
    "        # build the cmd\n",
    "        cmd = f'vtpdetect {evts}[pi=50:600] {expmap} {outfits} '\n",
    "        for param, value in list(params.items()):\n",
    "            cmd += f'{param}={value} '\n",
    "        f.writelines(f'{cmd}\\n')\n",
    "\n",
    "    os.system(cmd)\n",
    "\n",
    "    # now for the higher level\n",
    "    params['regfile'] = f'{outpath}/{name}/{name}_vtp_high.reg'\n",
    "    params['log'] = f'{outpath}/{name}/{name}_vtp_high.log'\n",
    "    params['scale'] = 1.8\n",
    "    outfits = f'{outpath}/{name}/{name}_vtp_high.detect'\n",
    "    with open(f'{outpath}/{name}/{name}_vtp_high.in', 'w') as f:\n",
    "        # build the cmd\n",
    "        cmd = f'vtpdetect {evts}[pi=50:600] {expmap} {outfits} '\n",
    "        for param, value in list(params.items()):\n",
    "            cmd += f'{param}={value} '\n",
    "        f.writelines(f'{cmd}\\n')\n",
    "\n",
    "    os.system(cmd)\n",
    "\n",
    "    ###\n",
    "    # Now we are building the final catalog by comparing the low and high scale catalogs.\n",
    "    ###\n",
    "    try:\n",
    "        low = Table.read(f'{outpath}/{name}/{name}_vtp_low.detect', hdu=1)\n",
    "        high = Table.read(f'{outpath}/{name}/{name}_vtp_high.detect', hdu=1)\n",
    "    except FileNotFoundError:\n",
    "        return\n",
    "\n",
    "    # create a new table to store our results -- just makes an empty copy of the original\n",
    "    final = Table(dtype=low.dtype)\n",
    "    final.add_column(Column(name='INDEX', dtype='>i4'), index=0)\n",
    "    final.add_column(Column(name='HIGH', dtype='>i4'))\n",
    "                                                                               \n",
    "    # have to add columns to the original tables to make them match\n",
    "    low.add_column(Column(data=np.zeros(len(low)), name='INDEX', dtype='>i4'), index=0)\n",
    "    low.add_column(Column(data=np.zeros(len(low)), name='HIGH', dtype='>i4'))\n",
    "    high.add_column(Column(data=np.zeros(len(high)), name='INDEX', dtype='>i4'), index=0)\n",
    "    high.add_column(Column(data=np.zeros(len(high)), name='HIGH', dtype='>i4'))\n",
    "\n",
    "    index = 1 # vtp is normally 1 indexed\n",
    "    for x_l, y_l, rad_l, rot_l, comp_l in low[['X', 'Y', 'R', 'ROTANG', 'COMPONENT']]:\n",
    "\n",
    "        added_high = False # keep track if we found a high source\n",
    "\n",
    "        for x_h, y_h, comp_h in high[['X', 'Y', 'COMPONENT']]:\n",
    "            if pointInEllipse(x_l, y_l, x_h, y_h, rad_l[0], rad_l[1], 360 - rot_l):\n",
    "                final.add_row(high[comp_h - 1]) # add the row\n",
    "                final['INDEX'][index - 1] = index # add the index to the row\n",
    "                final['HIGH'][index - 1] = 1 # say that the source came from high catalog\n",
    "                index += 1\n",
    "                added_high = True\n",
    "\n",
    "        if not added_high:\n",
    "            final.add_row(low[comp_l - 1]) # add the row\n",
    "            final['INDEX'][index - 1] = index # add the index to the row\n",
    "            final['HIGH'][index - 1] = 0 # say that the source came from low catalog\n",
    "            index += 1\n",
    "\n",
    "    # remove any source where the center of the region lies inside another region        \n",
    "            \n",
    "            \n",
    "            \n",
    "    final.write(f'{outpath}/{name}/{name}_vtp.detect', format='fits', overwrite=True)\n",
    "\n",
    "    # write out the regions\n",
    "    with open(f'{outpath}/{name}/{name}_vtp.reg', 'w') as reg:\n",
    "        reg.write(\"# Region file format: DS9 version 4.1\\n\")\n",
    "        reg.write('global color=cyan dashlist=8 3 width=1 font=\"helvetica 10 normal roman\" select=1 '\n",
    "                  'highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n')\n",
    "        reg.write('fk5\\n')\n",
    "        for j, xc, yc, rc, rotc in final[['INDEX', 'RA', 'DEC', 'R', 'ROTANG']]:\n",
    "            reg.write(f'ellipse({xc},{yc},{(rc[0] * 2.36):.3f}\",{(rc[1] * 2.36):.3f}\",{rotc:.3f}) ')\n",
    "            reg.write(f'# text={{{j}}}\\n')\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf(name, outpath, pp=None):\n",
    "    \n",
    "    with open(f'{outpath}/{name}/{name}_ximg_psf.in', 'w') as f:\n",
    "        # loop over the blocked images\n",
    "        for blk in [4, 8]:\n",
    "            # loop over the energies\n",
    "            for eng in [200, 300, 400, 500, 600]:\n",
    "                if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det'):\n",
    "                    continue\n",
    "\n",
    "                # figure out the background level\n",
    "                with open(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det', 'r') as f2:\n",
    "                    for l in f2.readlines():\n",
    "                        if 'Back' in l:\n",
    "                            background = float(l.split(':')[-1])\n",
    "                            break\n",
    "\n",
    "                # read the image\n",
    "                f.writelines(f'read {outpath}/{name}/{name}_img_50-{eng}_bl{blk}.fits\\n')\n",
    "\n",
    "                # now we need to read the individual detections\n",
    "                detects = Table.read(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det.fits')\n",
    "\n",
    "                # write psf commands for each detection\n",
    "                for i, (x, y) in enumerate(detects[['X', 'Y']]):\n",
    "                    f.writelines(f'psf/xpix={x}/ypix={y}/back={background}/radius=4.25/noplot/'\n",
    "                                f'fileplot={{{outpath}/{name}/{name}_img_50-{eng}_bl{blk}_{i}.psf}}\\n')\n",
    "\n",
    "                    \n",
    "        f.writelines('exit\\n')\n",
    "\n",
    "    # log output\n",
    "    log_file = f'{outpath}/{name}/{name}_ximg_psf.log'\n",
    "        \n",
    "    # call xselect\n",
    "    cmd = f'ximage < {outpath}/{name}/{name}_ximg_psf.in > {log_file}'\n",
    "    \n",
    "    os.system(cmd)\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(name, outpath):\n",
    "    ''' I dont think this code will actually work '''\n",
    "    \n",
    "    # loop over the blocked images\n",
    "    for blk in [4, 8]:\n",
    "        # loop over the energies\n",
    "        for eng in [200, 300, 400, 500, 600]:\n",
    "            if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det'):\n",
    "                continue\n",
    "\n",
    "            # now we need to read the individual detections\n",
    "            detects = Table.read(f'{outpath}/{name}/{name}_img_50-{eng}_bl{blk}.det.fits')\n",
    "\n",
    "            # write psf commands for each detection\n",
    "            for i, (ra, dec) in enumerate(detects[['RA', 'DEC']]):\n",
    "                with open(f'{outpath}/{name}/{name}_cent_50-{eng}_bl{blk}_{i}.in', 'w') as f:\n",
    "                    cmd = 'xrtcentroid '\n",
    "                    cmd += f'infile={outpath}/{name}/{name}_img_50-{eng}_bl{blk}.fits '\n",
    "                    cmd += f'outfile={name}_img_50-{eng}_bl{blk}_{i}.cent '\n",
    "                    cmd += f'outdir={outpath}/{name} '\n",
    "                    cmd += f'boxra={ra} '\n",
    "                    cmd += f'boxdec={dec} '\n",
    "                    cmd += 'calcpos=yes ' \n",
    "                    cmd += 'interactive=no '\n",
    "                    cmd += 'boxradius=1 '\n",
    "                    cmd += 'clobber=yes'\n",
    "\n",
    "                    f.writelines(cmd)\n",
    "\n",
    "                # log output\n",
    "                log_file = f'{outpath}/{name}/{name}_cent_50-{eng}_bl{blk}_{i}.log'\n",
    "\n",
    "                # call xselect\n",
    "                cmd = f'{cmd} > {log_file}'\n",
    "\n",
    "                os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_vtp(name, outpath):\n",
    "\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-600.fits'):\n",
    "        return\n",
    "    else:\n",
    "        evts = f'{outpath}/{name}/{name}_img_50-600.fits'\n",
    "        \n",
    "    # now we need to read the individual detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:    \n",
    "        detects = Table.read(f'{outpath}/{name}/{name}_vtp.detect')\n",
    "\n",
    "    if not os.path.isdir(f'{outpath}/{name}/centroids'):\n",
    "        os.makedirs(f'{outpath}/{name}/centroids')\n",
    "    \n",
    "    # xrtcentroid can't handle the '+' in the filename.. \n",
    "    # So we'll make a symlink\n",
    "    relpath = os.path.relpath(evts, f'{outpath}/{name}/centroids/')\n",
    "    try:\n",
    "        os.symlink(relpath, f'{outpath}/{name}/centroids/xrtcentroid.fits')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # write out the new regions\n",
    "    with open(f'{outpath}/{name}/centroids/{name}_newcentroid.reg', 'w') as reg:\n",
    "        reg.write(\"# Region file format: DS9 version 4.1\\n\")                   \n",
    "        reg.write('global color=cyan dashlist=8 3 width=1 font=\"helvetica 10 normal roman\" select=1 '\n",
    "                  'highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1\\n')\n",
    "        reg.write('fk5\\n')\n",
    "    \n",
    "        # write psf commands for each detection\n",
    "        for i, ra, dec, r, rotc in detects[['INDEX', 'RA', 'DEC', 'R', 'ROTANG']]:\n",
    "            cmd = 'xrtcentroid '\n",
    "            cmd += f'infile={outpath}/{name}/centroids/xrtcentroid.fits '\n",
    "            cmd += f'outfile={name}_{i}.cent '\n",
    "            cmd += f'outdir={outpath}/{name}/centroids '\n",
    "            cmd += f'boxra={ra} '\n",
    "            cmd += f'boxdec={dec} '\n",
    "            cmd += 'calcpos=yes ' \n",
    "            cmd += 'interactive=no '\n",
    "            cmd += f'boxradius={(max(r) * 2.36) / 60:0.3f} '\n",
    "            cmd += 'clobber=yes'\n",
    "\n",
    "            # log output\n",
    "            log_file = f'{outpath}/{name}/centroids/{name}_{i + 1}.log'\n",
    "\n",
    "            # call xselect\n",
    "            cmd = f'{cmd} > {log_file}'\n",
    "\n",
    "            os.system(cmd)\n",
    "\n",
    "            with open(f'{outpath}/{name}/centroids/{name}_{i}.cent', 'r') as cent:\n",
    "                cent.readline()\n",
    "                cent.readline()\n",
    "                ra = cent.readline().split('=')[-1].rstrip('\\n')\n",
    "                dec = cent.readline().split('=')[-1].rstrip('\\n')\n",
    "\n",
    "            reg.write(f'ellipse({ra},{dec},{(r[0] * 2.36):.3f}\",{(r[1] * 2.36):.3f}\",{rotc:.3f}) ')\n",
    "            reg.write(f'# text={{{i}}}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radprof(name, outpath, overwrite=False):\n",
    "            \n",
    "    # handle specific cases that take a LOOOOONNNGGG time\n",
    "    # these are the really big, nearby clusters\n",
    "    if name in ['PSZ2_G062.94+43.69', 'PSZ2_G164.18-38.88', \n",
    "                'PSZ2_G164.18-38.88', 'PSZ2_G302.41+21.60',\n",
    "                'PSZ2_G306.77+58.61', 'PSZ2_G061.75+88.11',\n",
    "                'PSZ2_G274.73-32.20', 'PSZ2_G302.49+21.53']:\n",
    "        return\n",
    "        \n",
    "    # Swift XRT pixel scale\n",
    "    # 1 pixel = 6.548089E-04 * 3600 arcsec\n",
    "    pixscale = 6.548089E-04 * 3600\n",
    "    \n",
    "    # model parameters\n",
    "    params = {}\n",
    "    params['n'] = 75\n",
    "    params['r0'] = 0 \n",
    "    params['dr'] = 4\n",
    "    \n",
    "    # check for files\n",
    "    # events image\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_img_50-200.fits'):\n",
    "        return\n",
    "    else:\n",
    "        evnts = f'{outpath}/{name}/{name}_img_50-200.fits'\n",
    "    # expo map\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_exp.fits'):\n",
    "        return\n",
    "    else:\n",
    "        expmap = f'{outpath}/{name}/{name}_exp.fits'   \n",
    "    # detections\n",
    "    if not os.path.isfile(f'{outpath}/{name}/{name}_vtp.detect'):\n",
    "        return\n",
    "    else:\n",
    "        srcs = f'{outpath}/{name}/{name}_vtp.detect'\n",
    "    \n",
    "    # now we need to read the individual detections\n",
    "    detects = Table.read(srcs, hdu=1)\n",
    "    \n",
    "    # we are going to compute profiles for the 10 biggest -- this is for speed. \n",
    "    detects.sort(['SRC_AREA'], reverse=True)\n",
    "    \n",
    "    # loop over the sources -- component is the source ID number\n",
    "    for i, xc, yc in detects[['INDEX', 'X', 'Y']][:10]:\n",
    "        # decide whether we need to redo the profile\n",
    "        if overwrite:\n",
    "            pass\n",
    "        elif os.path.isfile(f'{outpath}/{name}/{name}_vtp_{i}.radprof'):\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            data = Table.read(f'{outpath}/{name}/{name}_vtp_{i}.radprof', format='ascii', header_start=2)\n",
    "            if len(data) >= 70:\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "        # output file\n",
    "        with open(f'{outpath}/{name}/{name}_vtp_{i}.radprof', 'w') as radprof:\n",
    "            radprof.write(f\"# source number and position: {name}_{i} {xc:.3f} {yc:.3f}\\n\")\n",
    "            radprof.write(f\"# profile parameters: {params['n']} {params['r0']} {params['dr']}\\n\")\n",
    "            radprof.write(f\"# bin r1 r2 x y w sb sb_err\\n\")\n",
    "\n",
    "            fd2, path2 = tempfile.mkstemp() # this is the temp file to store the awk output\n",
    "            for irad in range(params['n']):\n",
    "                r1 = params['r0'] + irad * params['dr']\n",
    "                r2 = params['r0'] + (irad + 1) * params['dr']\n",
    "\n",
    "                fd, path = tempfile.mkstemp()\n",
    "                with os.fdopen(fd, 'w') as reg:\n",
    "                    reg.write(\"# Region file format: CIAO version 1.0\\n\")\n",
    "                    reg.write(f\"+annulus({xc},{yc},{r1},{r2})\\n\")\n",
    "                    for j, xc1, yc1, rc, rotc in detects[['INDEX', 'X', 'Y', 'R', 'ROTANG']]:\n",
    "                        if not j == i:\n",
    "                            reg.write(f\"-ellipse({xc1},{yc1},{rc[0]},{rc[1]},{rotc})\\n\")\n",
    "                          \n",
    "                #  No. of counts from data image\n",
    "                cmd = f\"dmstat '{evnts}[(x,y)=region({path})]' centroid- | grep sum | awk '{{print $2}}' > {path2}\"\n",
    "                #print(cmd)\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    x = tmp.readlines()[0][:-1]\n",
    "                x = float(x)\n",
    "\n",
    "                #  Mean exposure\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep mean | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    y = tmp.readlines()[0][:-1]\n",
    "                y = float(y)\n",
    "\n",
    "                #  No. of pixels\n",
    "                cmd = f\"dmstat \\\"{expmap}[(x,y)=region({path})]\\\" centroid- | grep good | awk '{{print $2}}' > {path2}\"\n",
    "                os.system(cmd)\n",
    "                with open(path2) as tmp:\n",
    "                    w = tmp.readlines()[0][:-1]\n",
    "                w = float(w)\n",
    "\n",
    "                os.remove(path)\n",
    "            \n",
    "                try:\n",
    "                    sb = x / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                    err_gehrels = sqrt(x + 0.75)\n",
    "                    sbe = (1. + err_gehrels) / (y * w * pixscale**2 / 3600)  #  cts/s/arcmin^2\n",
    "                    radprof.write(f\"{irad:3d} {r1:7d} {r2:7d} {x:9.1f} {y:9.1f} {w:9.1f} {sb:12.4e} {sbe:12.4e}\\n\")\n",
    "                except ZeroDivisionError:\n",
    "                    print(f'{name}_{i} -- Zero Division in sb calculation! -- bin number {irad:3d}')\n",
    "                    print(f'more info {w:.3f} {y:.3f}')\n",
    "\n",
    "            os.remove(path2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get file data\n",
    "data = load_PSZcatalog()\n",
    "data = data.sort_index(axis=1)\n",
    "\n",
    "outpath = './data_full'\n",
    "\n",
    "# arr = [{'name':n.replace(' ', '_'), 'outpath':outpath, 'overwrite':True} for n in data['NAME']]\n",
    "arr = [{'name':n.replace(' ', '_'), 'outpath':outpath} for n in data['NAME']]\n",
    "\n",
    "##########\n",
    "### these are legacy and don't really need to be run ###\n",
    "#parallel_process(arr, source_detect, use_kwargs=True)\n",
    "#parallel_process(arr, psf, use_kwargs=True)\n",
    "#parallel_process(arr, centroid, use_kwargs=True)\n",
    "##########\n",
    "\n",
    "\n",
    "# parallel_process(arr, detect_vtp, use_kwargs=True, n_jobs=1)\n",
    "parallel_process(arr, centroid_vtp, use_kwargs=True, n_jobs=6)\n",
    "#parallel_process(arr, get_radprof, use_kwargs=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = './data_full'\n",
    "name = 'PSZ2_G080.37+14.64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroid_vtp(name, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'PSZ2_G306.77+58.61'\n",
    "outpath = './data_full'\n",
    "get_radprof(name, outpath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
